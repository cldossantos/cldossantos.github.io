{
  "hash": "55878d28e581d753c8506d8721fd92ac",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Working with yield monitor data\"\nauthor: \"Caio dos Santos\"\ndate: \"2025-03-10\"\ncategories: [pacu, yield monitor]\n---\n\n\n\n## Introduction\n\nWorking with yield monitor data can be quite challenging. The data can have several sources of error and accounting for all of them can be hard. For instance, there are instances in which the combine travels through an area that has been previously harvested, artificially recording low yielding points. There can also uncertainties associated with the combine travelling fast or slow, changing the effective harvested area from one observation to the next. There are many other instances in which we can end up with inadequate data when working with yield monitor data but this blog post cannot list all of them.\n\nI wanted to give you an example of how we can use *pacu* to address some of these challenges. For that, we will use a data set contained in the [agridat](https://kwstat.github.io/agridat/) package.\n\n## Installing and loading the necessary packages\n\nIf you have not done so, you can install the *agridat* package using the following line of code:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages('agridat')\n```\n:::\n\n\n\nTo install *pacu*, you can either install the CRAN version:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages('pacu')\n```\n:::\n\n\n\nOr, you can install the development version from GitHub using the *remotes* package:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nremotes::install_github('cldossantos/pacu')\n```\n:::\n\n\n\nNow that we have installed the necessary packages we can load them and continue with our analysis.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pacu)\nlibrary(sf)\nlibrary(agridat)\n```\n:::\n\n\n\n\n\n## Working with the data\n\nThe *agridat* package contains a data set of yield observations collected from a corn field in Minnesota, the data set name is [gartner.corn](https://kwstat.github.io/agridat/reference/gartner.corn.html).\\\nHere, we load the data set and look at the first rows:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"gartner.corn\")\nhead(gartner.corn)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       long      lat  mass time seconds dist moist    elev\n1 -93.97842 43.92726 16.54    0       3  116  18.5 1030.58\n2 -93.97842 43.92723 22.52    3       3  159  16.7 1030.58\n3 -93.97842 43.92718 27.01    6       3  169  17.2 1029.92\n4 -93.97842 43.92713 30.24    9       3  221  17.2 1029.92\n5 -93.97842 43.92708 30.95   12       3  234  17.3 1029.59\n6 -93.97842 43.92702 33.57   15       3  227  17.5 1029.59\n```\n\n\n:::\n:::\n\n\n\nThere are a couple pieces of information that we need but that are currently not included in the data set. Namely, we need the combine swath and the yield. In the [help page](https://kwstat.github.io/agridat/reference/gartner.corn.html) the author provided more information that can come in handy. For instance, he told us that the combine swath is 360 inches and provided a formula to calculate yield from the information in the data set. The yield will be calculated in units of bushel/acre. Let's follow his formula:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngartner.corn$swath <- 360\ngartner.corn$dry.grain <-  with(gartner.corn, (mass * seconds * (100-moist) / (100-15.5)) / 56) \ngartner.corn$harvested.area <-  with(gartner.corn, (dist * swath) / 6272640) \ngartner.corn$yield <- with(gartner.corn, dry.grain / harvested.area)\n```\n:::\n\n\n\n\n## Renaming some of the variables\n\nHere, I rename some of the variables so that it is easier for me to understand what they represent.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(gartner.corn) <- c('long', 'lat', 'flow', 'time', 'interval', 'distance', 'moisture', 'elevation', 'swath', 'dry.grain', 'harvested.area', 'yield')\n```\n:::\n\n\n\nNow that we have added the necessary columns, we can convert the data frame into a [sf](https://r-spatial.github.io/sf/) object. The *sf* library has several methods for working with spatial data and *pacu* is heavily built upon those. We can also plot the data to look into the spatial patterns of the variables:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nyield.data <- st_as_sf(gartner.corn, \n                       coords = c('long', 'lat'),\n                       crs = 'epsg:4326')\nplot(yield.data)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n\n\n## Looking at the yield data\n\nIf we focus on the yield (bu/ac), we can see some interesting features of this field. It seems like there is a waterway in the northern part of the field and there is an area in the mid-lower east part of the field that has lower yields.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(yield.data['yield'], pch = 15)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\nSomething that can also catch our attention is just how variable this data is. Let's take a look at the distribution of the data as well. We can see that most of the data is between 100 and 160 bu/ac but the data ranges from 0 to 258 bu/ac.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(density(yield.data$yield), main = '')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n## Considerations about cleaning the data\n\nThis kind of variability can be dealt with a variety of approaches. There are researchers who have proposed that we can remove anything that falls outside of 2 or 3 standard deviations from the mean. This is an empirical rule based on the assumption that the yield data follows a normal distribution. These thresholds represent $\\approx95.0\\%$ and $\\approx99.7\\%$ of the probability mass function of a normal distribution, respectively. However, this is based on two assumptions that are violated from the beginning:\n\n1.  *Independent samples*: these are correlated in space\n2.  *Normal distribution*: there is no guarantee this data will follow a normal distribution. These data are bound to be greater than zero.\n\nThere is ultimately no magical formula for cleaning yield data. Some of the empirical rules can work for some data sets but not for others. *pacu* offers options that do not rely on these rules but I feel that this is a subject for a different post.\n\n## Producing a yield map\n\nTo produce a yield map using *pacu*, we will use the *pa_yield()* function. The package offers two algorithms: *simple* and *ritas*. In this post I will not go into much detail about the algorithms. There is more information about this in this [paper](https://doi.org/10.1016/j.softx.2024.101971).\n\nIn this case, I will go straight to the *ritas* algorithm. The ritas algorithm involves several computationally intensive processes. To accelerate this process, we have enabled parallelization. The user can control this using the *cores* argument. Keep in mind though that parallelization has diminishing returns! \n\nI did not supply units in this case because the *pa_yield()* function attempts to guess the units and I wanted to demonstrate that functionality. However, this is based on very simple rules and the function can make a mistake. In that case, the user can override the guess by passing the argument *data.units*.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nyld <- pa_yield(input = yield.data, \n                algorithm = 'ritas',\n                unit.system = 'metric',\n                moisture.adj = 15.5,\n                cores = 5,\n                verbose = FALSE)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nGuessing units of interval to be s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nGuessing units of moisture to be %\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nGuessing units of flow to be lb/s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nGuessing units of width to be in\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nGuessing units of distance to be in\n```\n\n\n:::\n:::\n\n\n\nTo look at the yield map, we can use the *pa_plot()* function.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npa_plot(yld, legend.outside = TRUE)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\n## Conclusion\n\nWe have looked into how we can build yield maps from raw yield monitor data using *pacu*. This is a case in which we are processing the data at the field level. In a case in which we are processing data from on-farm experiments, there are a few more considerations we need to make. This is a subject for a future post! ",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}