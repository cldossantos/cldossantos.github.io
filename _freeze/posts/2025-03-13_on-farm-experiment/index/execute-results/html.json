{
  "hash": "5f04153067efc0de5c16d7e5690cfdad",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Working with yield monitor data\"\nauthor: \"Caio dos Santos\"\ndate: \"2025-03-13\"\ncategories: [pacu, yield monitor]\n---\n\n\n\n## Introduction\n\nIn a previous post, I have mentioned that *pacu* provided support for processing data coming from on-farm trials, as well as production fields. In this post, I want to explore and showcase this functionality a little more in depth. The idea is to provide an example of processing these data and make a few considerations that can greatly impact the end result. \n\nWe will look at simulated data from a small on-farm trial. This is made up data and I simulated a relationship between corn yield and nitrogen rate that followed a linear plateau relationship like the image below. The simulated relationship presented an intercept = 7000, slope = 30, and a breakpoint = 180. Let's process this data and see if we can recover this relationship.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n\n\n## Installing and loading the necessary packages\n\nTo install *pacu*, you can either install the CRAN version:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages('pacu')\n```\n:::\n\n\n\nOr, you can install the development version from GitHub using the *remotes* package:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nremotes::install_github('cldossantos/pacu')\n```\n:::\n\n\n\nNow that we have installed the necessary packages we can load them and continue with our analysis.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pacu)\nlibrary(sf)\nlibrary(nlraa)\nlibrary(nlme)\n```\n:::\n\n\n\n\n\n## Working with the data\n\nHere, we will import the data sets into R. We will use to data sets for this exercise. The first contains made up raw yield data that represents data coming from an on-farm trial. The second contains an example of nitrogen rates applied to each experimental unit.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nraw.yield <- read_sf('./raw-data/example-raw-data.shp',\n                     quiet = TRUE)\n\ntrial.design <- read_sf('./raw-data/example-trial-design.shp',\n                     quiet = TRUE)\n```\n:::\n\n\n\nLets take a look at how these two data sets line up in space. In this example, the points represent the yield monitor readings and the red rectangles represent the experimental units. We can see that, in this example, we had about 4 combine passes per experimental unit.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(st_geometry(raw.yield), pch = 1, cex = 0.3)\nplot(st_geometry(trial.design), border = 'red', add = TRUE)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\nAnother piece of information that can be extracted from the *trial.design* data set is the amount of nitrogen applied to each experimental unit in this example.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(trial.design[\"nrate\"], main = 'Nitrogen rate (kg/ha)')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n\nWe can take a look at the raw yield data to see the kind of data we are dealing with. We can see that there is a lot of variability in the yield data, with it ranging from $\\approx 200$ to $\\approx 12000$ kg/ha. Some of this variability comes from the treatment effect but there's a part of it that is just random variability. The challenge lies in parsing out the treatment effect.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboxplot(raw.yield$yld_kgh,\n        ylab = 'Yield (kg/ha)')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(raw.yield[\"yld_kgh\"],\n     pch = 16,\n     main = 'Yield (kg/ha)',\n     breaks = 'quantile',\n     reset = FALSE)\nplot(st_geometry(trial.design),\n     add = TRUE)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-2.png){width=672}\n:::\n:::\n\n\n\n## Cleaning based on standard deviation\n\nSomething that is common to do, is to use empirical rules to remove outliers and clean some of the noise inherent to these type of data, let's see the effect of that.\n\nA pretty common procedure is to clean anything outside of 2 or 3 standard deviations from the mean (you can read more about it [here](https://cldossantos.github.io/posts/2025-02-11_yield-map/).\nLet us take a look at this procedure. I will isolate one experimental unit for us to take a closer look. The removed points are marked with a red \"X\". For this experimental unit, anything that was smaller tha 5622 or greater than 8139 kg/ha was removed.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## selecting only experimental unit 5\nto.keep <- as.numeric(st_intersects(raw.yield, trial.design[5, ]))\none.eu <- raw.yield[!is.na(to.keep), 'yld_kgh']\n\n## calculating the mean and sd\neu.mean <- mean(one.eu[['yld_kgh']])\neu.sd <- sd(one.eu[['yld_kgh']])\n\n## defining upper and lower boundaries and identifying which\n## data points to remove\nupper.boundary <- eu.mean + 2 * eu.sd\nlower.boundary <- eu.mean - 2 * eu.sd\nto.remove <- (one.eu$yld_kgh < lower.boundary | \n                one.eu$yld_kgh > upper.boundary)\n\n## showing which points were removed\nplot(one.eu, reset = FALSE,\n     main = 'Yield (kg/ha)',\n     pch = 16)\nplot(st_geometry(one.eu)[to.remove],\n     cex = 2,\n     col = 'red',\n     pch = 'x', \n     add = TRUE)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\nWe can now apply this same methodology to all experimental units and see that, in total, we will remove 60 points from this data set. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nraw.yield$eu <- as.numeric(st_intersects(raw.yield, trial.design))\nraw.yield <- raw.yield[order(raw.yield$eu), ]\nto.remove <- ave(raw.yield$yld_kgh, \n                 raw.yield$eu,\n                 FUN = function(x){\n                   eu.mean <- mean(x)\n                   eu.sd <- sd(x)\n                   upper.boundary <- eu.mean + 2 * eu.sd\n                   lower.boundary <- eu.mean - 2 * eu.sd\n                    (x < lower.boundary | x > upper.boundary)\n                 })\nto.remove <- as.logical(to.remove)\n\nplot(raw.yield['yld_kgh'], \n     main = 'Yield (kg/ha)',\n     reset = FALSE,\n     pch = 16)\nplot(st_geometry(raw.yield)[to.remove],\n     col = 'red',\n     pch = 'x', \n     add = TRUE)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nNow, let us remove these data points, and average the yield observations within each experimental unit. We can see that our estimates of the model parameters are not quite the same ones that we simulated. In addition, the variance of the parameter estimates is pretty large. This means that we are not very certain of these values.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nyield.filtered.sd <- raw.yield[!to.remove, ]\nmean.yield.sd <- aggregate(yield.filtered.sd['yld_kgh'],\n                           trial.design,\n                           FUN = mean)\nmean.yield.sd <- st_join(mean.yield.sd, trial.design, join = st_equals)\nplot(mean.yield.sd$nrate, mean.yield.sd$yld_kgh, \n     xlab = 'Nitrogen rate (kg/ha)', ylab = 'Yield (kg/ha)')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n\n```{.r .cell-code}\nfit1 <- nls(yld_kgh ~ SSlinp(nrate, a, b, xs),\n            data = mean.yield.sd)\n# estimates\ncoef(fit1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         a          b         xs \n6814.09790   28.01518  168.74310 \n```\n\n\n:::\n\n```{.r .cell-code}\n# variances\ndiag(vcov(fit1))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           a            b           xs \n28833.979455     3.075624    71.175162 \n```\n\n\n:::\n:::\n\n\n## Adding a buffer to the experimental units\n\nAnother empirical cleaning method that is commonly used is to add a buffer to the experimental units. This in meant to remove some of the border effect or the transition between experimental units. However, adding a buffer needs to be done with caution. You want you buffer to be big enough to remove some of these potentially problematic points, but you do not want your buffer to remove so many points that you will end up estimating the mean with fewer points. This would increase the uncertainty of your estimate. Let's take a look at different buffer sizes:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbuffers <- c(1, 2, 5, 10)\ncols <- hcl.colors(4, palette = 'Temps')\nplot(st_geometry(raw.yield), cex = 0.5)\nfor (i in 1:length(buffers)){\n  buffered.exp.units <- st_as_sf(st_buffer(trial.design, -buffers[i]))\n  plot(st_geometry(buffered.exp.units), border = cols[i], add = TRUE)\n}\nlegend('topleft', \n       fill = cols,\n       legend = buffers,\n       title = 'Buffer size (m)')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n\nIt seems that a buffer size of about 5 meters is what we want. Let's go with that and see which observations will be removed from the data set:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbuffered.exp.units <- st_as_sf(st_buffer(trial.design, -5))\nraw.yield$eu <- as.numeric(st_intersects(raw.yield, buffered.exp.units))\nraw.yield <- raw.yield[order(raw.yield$eu), ]\nto.remove <- ave(raw.yield$yld_kgh, \n                 raw.yield$eu,\n                 FUN = function(x){\n                   eu.mean <- mean(x)\n                   eu.sd <- sd(x)\n                   upper.boundary <- eu.mean + 2 * eu.sd\n                   lower.boundary <- eu.mean - 2 * eu.sd\n                    (x < lower.boundary | x > upper.boundary)\n                 })\n\nto.remove <- as.logical(to.remove)\n\nplot(raw.yield['yld_kgh'], \n     main = 'Yield (kg/ha)',\n     reset = FALSE,\n     pch = 16)\nplot(st_geometry(raw.yield)[to.remove],\n     col = 'red',\n     pch = 'x', \n     add = TRUE)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\nNow, let us remove these data points, and average the yield observations within each experimental unit. We can see that our estimates of the model parameters are a little closer to the true values but still not quite there. Also, the variance has decreased quite a bit.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nyield.filtered.buffer <- raw.yield[!to.remove, ]\nmean.yield.buffer <- aggregate(yield.filtered.buffer['yld_kgh'],\n                           trial.design,\n                           FUN = mean)\nmean.yield.buffer <- st_join(mean.yield.buffer, trial.design, join = st_equals)\nplot(mean.yield.buffer$nrate, mean.yield.buffer$yld_kgh, \n     xlab = 'Nitrogen rate (kg/ha)', ylab = 'Yield (kg/ha)')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n\n```{.r .cell-code}\nfit2 <- nls(yld_kgh ~ SSlinp(nrate, a, b, xs),\n            data = mean.yield.buffer)\n## estimates\ncoef(fit2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        a         b        xs \n6659.5802   30.3704  172.9306 \n```\n\n\n:::\n\n```{.r .cell-code}\n## variances\ndiag(vcov(fit2))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          a           b          xs \n6649.190326    0.709247   14.583390 \n```\n\n\n:::\n:::\n\n\n\n\nWe get a little closer to the true value with every layer of \nprocessing that we include in this exercise. However, these layers are \nempirical and somewhat arbitrary. By adding a buffer zone, we are looking to remove points that have an influence from the adjacent experimental units. This can be done using the *ritas* algorithm within *pacu*.\n\n## Using pa_yield\n\nThe pa_yield function has built-in capabilities to automate these processes without the need for these empirical rules. For instance, by setting *remove.crossed.polygons* to *TRUE*, we remove data that could be influenced by adjacent experimental units.\n\nSo we can visualize these steps, I will set the option *steps* to *TRUE*. This is a new addition to the package and is not yet available on CRAN. Please install the package from [GitHub](https://github.com/cldossantos/pacu) to be able to use this.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nyld3 <- pa_yield(raw.yield,\n                 data.columns = c(mass = 'mass_g',\n                                  interval = 'intrvl_',\n                                  distance = 'dstnc_f',\n                                  width = 'swth_ft',\n                                  angle = 'angl_dg',\n                                  moisture = 'moistur'),\n                 grid = trial.design,\n                 steps = TRUE,\n                 algorithm = 'ritas',\n                 unit.system = 'metric',\n                 verbose = FALSE,\n                 remove.crossed.polygons = TRUE,\n                 cores = 5)\n\nyld4 <- st_join(yld3$yield, trial.design, join = st_equals)\nyld4$yield_kgh <- yld4$yield * 1000\nfit3 <- nls(yield_kgh ~ SSlinp(nrate, a, b, xs),\n            data = yld4)\n\n## estimates\ncoef(fit3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         a          b         xs \n6997.17524   30.40087  176.09137 \n```\n\n\n:::\n\n```{.r .cell-code}\n## variances\ndiag(vcov(fit3))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           a            b           xs \n1401.4136937    0.1494841    3.1692490 \n```\n\n\n:::\n:::\n\n\n\n\n## Conclusion\n\nIn this exercise, we have seen how different decisions about data processing can affect the estimates we get from the data. We have also seen how we can use the *pa\\_yield()* function to process the yield data coming from agronomic trials. The differences in the precision of the estimates are really important when we want to estimate confidence intervals or investigate whether a certain covariate has an effect. For instance, let's say that, in addition to nitrogen rates, we also had nitrogen source. More precise estimates would increase the power of our analysis to find differences.",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}