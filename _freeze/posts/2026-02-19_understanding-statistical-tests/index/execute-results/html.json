{
  "hash": "1eb7601ea439fed2bb252133054c4ab4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Understanding Statistical Tests\"\nsubtitle: \"AGRON 5130 - Module 5\"\nauthor: \"Caio dos Santos\"\ndate: \"2026-02-19\"\noutput:\n  html_document:\n    toc: true\n    toc_float: true\n    theme: flatly\n    highlight: tango\n    smooth: false\n---\n\n\n\n\n\n# What are we actually doing when we run a test?\n\nSo far in this course, we have:\n\n- Described populations using the normal distribution  \n- Learned about sampling variability  \n- Introduced the $t$-distribution  \n- Compared two treatments using a paired $t$-test  \n- Computed confidence intervals  \n- Used `t.test()` in R  \n\nBut today I want to slow down and ask a more\nfundamental question:\n\n> What is a statistical test actually doing?\n\nWhen you click `Run` on a $t$-test in R and see a\np-value, what just happened?\n\nToday I want to dive more into every aspect of a\nstatistical test. I believe this is a good place to\ndo this because we will explore more complex tests\nand trial designs from now on, and the $t$-test\nprovides a simple framework to explain these\ntopics.\n\n---\n\n# Research Question\n\nBefore we run any test, and ideally before we\nconduct the trial, we should think of the research\nquestion. Not only will the research question\nguide our statistical test, it will also guide our\nexperimental design and which measurement should\nwe make.\n\nLet's look at an example from last module. We were\ninterested in asking whether corn following cereal\nrye presented a yield difference. In this case, our\nresearch question can be stated as:\n\n> Does corn yield following cereal rye differ from\ncorn yield following fallow?\n\nNotice that the research question contains no\njudgment of good/bad. From the research question,\nwe understand what measurements to make (yield),\nwhat our treatments are (cereal rye vs. no cereal\nrye), and we can derive our hypothesis.\n\nThis is different from some of the questions we\nask, which do not tell us how to conduct a\nstatistical test. For example:\n\n- Is cereal rye bad?\n- Are cover crops good? \n- Do cover crops make corn perform better?\n\n---\n\n# Last module's example\n\nNow that we talked about the research question, I\nthink it would be productive for us to exemplify\nhow we go from the question to the statistical\ntest. Let's focus on last week's rye or no rye\nexample.\n\n\n## Hypotheses\n\nFrom the research question, we can draw the\nfollowing competing statements.\n\n$$H_0: \\mu_{rye} = \\mu_{no~rye} \\newline  \nH_a: \\mu_{rye} \\neq \\mu_{no~rye} $$\n\nA statistical test does not prove Ha. It evaluates\nwhether the data are compatible with $H_0$\n\n\nNotice that the alternative hypothesis ($H_a$) is\ncompatible with the language used in the research\nquestion, which states whether there's a\ndifference in yield.\n\nIf the research question stated whether there's a\nreduction in corn yield, our hypothesis would have\nto be adjusted. So far, in this course, I have not\nmade that distinction to keep things simple, but\nwe will explore this a little more in depth when\nwe talk about one-sided versus two-sided\n$t$-tests.\n\n## The Linear Additive Model Behind the $t$-Test\n\nUp to this point, we have written hypotheses using\nsymbols. But underneath every hypothesis test is a\nmodel.\n\nFor the rye example, the paired $t$-test can be\nwritten as a linear additive model:\n\n$$Y_{ij} = \\mu + \\tau_i + \\epsilon_{ij}$$ Where\n$i$ indexes the treatment (rye, no rye), and $j$\nindexes the observation for that treatment (every\nstrip).\n\nLet’s slow down and unpack this.\n\n$Y_{ij}$ = observed yield \n\n$\\mu$ = overall mean yield\n\n$\\tau_i$ = treatment effect (rye or no rye)\n\n$\\varepsilon_{ij}$ = random error\n\nThis equation says:\n\nObserved yield = overall average + treatment effect + random variability\n\n\n\n### Looking deeper into the data\n\nLet's take a look at the rye example and explore what each model parameter represents. As a reminder, let's look at the data below:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\nSince we were looking at the difference between\npaired plots, we can represent it as the\ndifference between plots. In this plot, the open\ncircles represent the individual differences for\nevery pair, and the filled triangle represents the\nmean difference.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nRemember, we are testing for differences among the\ntreatments. In summary, we are testing whether our\ndifference is zero. Because we are analyzing\npaired differences, the overall mean cancels out,\nand the model simplifies to:\n\n$$\\Delta Y_{ij} =  \\tau_i + \\epsilon_{ij}$$ \nAnd the hypothesis we are testing is:\n\n$$H_0: \\tau_i = 0 \\newline  \nH_a:  \\tau_i \\neq 0$$\n\n\n\nLet's start with identifying $\\tau_i$ first. Since\n$\\tau_i$ is the mean difference between the\ntreatments:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\nOk, we were able to identify $\\tau_i$ in the\ngraph. So it's easier to see, let's spread the\nindividual observations along the y-axis and\nidentify the errors ($\\epsilon_{ij}$). The\ndistance between the points and the $\\tau_i$ line\nare the errors for each plot.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n##  The test statistic\n\nFor the paired $t$-test:\n\n$$T = \\frac{\\bar{x} − \\mu}{\\frac{s}{\\sqrt{n}}} = \\frac{mean~difference − 0}{standard~error}$$\n\nNotice:\n\n- Numerator = signal  \n- Denominator = noise  \n\nStatistical tests measure signal relative to\nvariability.\n\nLarge signal relative to noise → large |T| → small\np-value.\n\n\n## Interpreting the $t$-test output\n\nAfter running a paired $t$-test, you obtained:\n\n````\n\tPaired t-test\n\ndata:  rye_wide$Yield.Control and rye_wide$`Yield.Cereal Rye`\nt = 2.3366, df = 11, p-value = 0.03941\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n  0.3756842 12.5743158\nsample estimates:\nmean difference \n          6.475 \n````\n\n\nRounding that p-value to 0.04, what does 0.04 actually mean?\n\nIt does **NOT** mean:\n\n- There is a 4% chance rye reduces yield  \n- There is a 4% chance the null hypothesis is true  \n- There is a 96% chance rye hurts yield  \n\nIt means:\n\n> If there were truly no difference in yield\nbetween rye and no rye, we would observe a\n$t$-statistic this or more extreme only\nabout 4% of the time due to random sampling\nvariability.\n\n\n\n---\n\n# Errors of Statistical Tests\n\nI would love to come here and tell you that\nstatistical tests make no mistakes. However, due\nto the random nature of sampled data, this is not\ntrue.\n\nThere are two instances in which we can make an error. See the table below:\n\n||Reject $H_0$|Fail to Reject $H_0$|\n|:---|:---|:---|\n|$H_0$ is true|Type I Error|$\\checkmark$|\n|$H_0$ is false|$\\checkmark$| Type II Error|\n\n## Type I and Type II Errors\n\nSince we are dealing with randomness, each of\nthese error sources have their own probability.\nLet's take a look:\n\nType I Error:\n\n- Rejecting $H_0$ when it is true. \n- This is a\nthreshold we set when conducting the test.\n- Probability = α (often 0.05).\n\nType II Error:\n\n- Failing to reject $H_0$ when it is false.  \n- This is how often do we fail to identify a true effect. \n- Probability = β.\n\nThese errors reflect uncertainty in decision-making.\n\n---\n\n# Statistical Power\n\nPower is the probability that we correctly detect\na true effect. It would be amazing if we could\nmaximize **power** and **reduce** Type I error at\nthe same time. However, it's not how it works.\n\n## Thinking of this trade-off\n\nWhen we decrease the significance level\n($\\alpha$), we decrease the probability of Type I\nerror. However, even if $H_0$ is false, we need\nthe $|T|$ to be bigger in order to reject $H_0$.\nThus, we also decrease the power of our\nstatistical test.\n\nLook at the plots below, for example, if we have\n30 samples ($n=30$), going from $\\alpha=0.05$ to\n$\\alpha=0.01$, means that $|T|$ needs to be more\nextreme than 2.75, instead of 2.05, making the\ntest stricter.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(fastGraph)\nx <- seq(-3, 3, 0.1)\nt05 <- qt(c(0.025, 0.975), 29)\nt01 <- qt(c(0.005, 0.995), 29)\n\nshadeDist(t05, 'dt', parm2 = 29)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\nshadeDist(t01, 'dt', parm2 = 29)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-2.png){width=672}\n:::\n:::\n\n\n\nIn agronomy, low power means:\n\n- Real treatment effects may go undetected  \n- Management recommendations may be based on insufficient replication  \n\nPower depends on:\n\n1. Effect size  \n2. Variability  \n3. Sample size  \n4. Significance level (α)\n\nMore replication → smaller standard error → greater power.\n\n---\n\n\n# One-sided hypothesis\n\nSo far, we have explored two-sided hypotheses\nextensively. The majority of our work has been\nlooking at evidence of a difference, and this\ndifference could occur in any direction.\n\nFor example, this was the hypothesis for the rye\ntrial we have been exploring:\n\n$$H_0: \\mu_{rye} = \\mu_{no~rye} \\newline  \nH_a: \\mu_{rye} \\neq \\mu_{no~rye} $$\n\n\nNow, imagine that you do not just want to test\nwhether there a difference, let's say you research\nquestion as stated as:\n\n> Does corn yield **less** following cereal rye in\ncomparison to corn yield following fallow?\n\nThen, your hypothesis would change accordingly to:\n\n$$H_0: \\mu_{rye} \\geq \\mu_{no~rye} \\newline  \nH_a: \\mu_{rye} < \\mu_{no~rye} $$\n\nThe difference is subtle but important. Let's take\na look at what this means for our $t$-test. I will\npaste the $t$-test output here again for us:\n\n````\n\tPaired t-test\n\ndata:  rye_wide$Yield.Control and rye_wide$`Yield.Cereal Rye`\nt = 2.3366, df = 11, p-value = 0.03941\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n  0.3756842 12.5743158\nsample estimates:\nmean difference \n          6.475 \n````\n\n\nWhen we were working with a two-sided hypothesis,\na more extreme $t$-value could mean $t\\leq -2.3366$\nor $t\\geq2.3366$.\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n\nNow, however, under the one-sided hypothesis, we\nare looking only at the lower tail of the\ndistribution. We can see that the p-value is now\nonly half of what it was before.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\nCorrectly specifying whether the $t$-test is\none-sided or two-sided has important implications.\nLogically, if you assume $\\alpha = 0.05$, and\nyou're only using one-sided of the distribution,\nthe $t$-value will be closer to zero in order to\nmaintain the 5% of the probability distribution\narea. Let's see an example.\n\n\nUsing both sides of the $t$-distribution:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nUsing only the lower tail:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nIt's important to make sure the hypothesis and the\nresearch questions are aligned, as this will\ngreatly influence the results of your statistical\ntest.\n\n\n\n## Conducting a one-sided $t$-test in R\n\nGreat, now we understand the difference between\none-sided tests and two-sided tests. How do we\nimplement them?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrye <- read.csv('./data/cover-crop.csv')\nryew <- reshape(rye, \n                idvar = 'Block',\n                timevar = 'Treatment',\n                direction = 'wide')\nt.test(ryew$`Yield.Cereal Rye`,\n       ryew$Yield.Control, \n       paired = TRUE,\n       alternative = 'less')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPaired t-test\n\ndata:  ryew$`Yield.Cereal Rye` and ryew$Yield.Control\nt = -2.3366, df = 11, p-value = 0.01971\nalternative hypothesis: true mean difference is less than 0\n95 percent confidence interval:\n      -Inf -1.498288\nsample estimates:\nmean difference \n         -6.475 \n```\n\n\n:::\n:::\n\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}