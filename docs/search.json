[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "",
    "section": "",
    "text": "I have received my Ph.D. from the Department of Agronomy at Iowa State University with a Minor in Statistics. My research integrates crop physiology, digital agriculture, and statistical modeling to improve management and quantification of spatio- temporal variability in cropping systems. Much of my research has centered on physiological responses to nutrient availability, photoperiod, temperature, and genotype-by-environment interactions. I have worked extensively on tissue analysis, canopy dynamics, and phenological development in corn, soybean, and cover crops."
  },
  {
    "objectID": "about.html#about",
    "href": "about.html#about",
    "title": "",
    "section": "",
    "text": "I have received my Ph.D. from the Department of Agronomy at Iowa State University with a Minor in Statistics. My research integrates crop physiology, digital agriculture, and statistical modeling to improve management and quantification of spatio- temporal variability in cropping systems. Much of my research has centered on physiological responses to nutrient availability, photoperiod, temperature, and genotype-by-environment interactions. I have worked extensively on tissue analysis, canopy dynamics, and phenological development in corn, soybean, and cover crops."
  },
  {
    "objectID": "about.html#research-interests",
    "href": "about.html#research-interests",
    "title": "",
    "section": "Research interests",
    "text": "Research interests\nThere are several research areas that fascinate me. A short list of those would be: crop physiology, crop models, remote sensing, soil fertility, and statistical models."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "",
    "section": "Education",
    "text": "Education\n\nPh.D. in Crop Production and Physiology\n\nMinor in Statistics\nIowa State University\n2020 - 2025\n\nM.Sc. in Crop, Soil, and Environmental Sciences\n\nUniversity of Arkansas\n2018 - 2020\n\nB.Sc. in Agronomy\n\nCollege of Agriculture “Luiz de Queiroz”\nUniversity of Sao Paulo\n2013 - 2018"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "Multiple Treatment Trials\n\n\nModule 6\n\n\n\nstatistics\n\n\n\n\n\n\n\n\n\nFeb 23, 2026\n\n\nCaio dos Santos\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Statistical Tests\n\n\nModule 5\n\n\n\nstatistics\n\n\n\n\n\n\n\n\n\nFeb 19, 2026\n\n\nCaio dos Santos\n\n\n\n\n\n\n\n\n\n\n\n\nComparisons between two treatments\n\n\nModule 4\n\n\n\nstatistics\n\n\n\n\n\n\n\n\n\nFeb 5, 2026\n\n\nCaio dos Santos\n\n\n\n\n\n\n\n\n\n\n\n\nSample Statistics\n\n\nModule 3\n\n\n\nstatistics\n\n\n\n\n\n\n\n\n\nFeb 2, 2026\n\n\nCaio dos Santos\n\n\n\n\n\n\n\n\n\n\n\n\nProbability and Distributions\n\n\nModule 2\n\n\n\nstatistics\n\n\n\n\n\n\n\n\n\nJan 26, 2026\n\n\nCaio dos Santos\n\n\n\n\n\n\n\n\n\n\n\n\nExperimental Design - How many controls to include in a factorial experiment?\n\n\n\n\n\n\nexperimental design\n\n\n\n\n\n\n\n\n\nDec 3, 2025\n\n\nCaio dos Santos\n\n\n\n\n\n\n\n\n\n\n\n\nProcessing as-applied and as-planted data in on-farm trials\n\n\n\n\n\n\npacu\n\nyield monitor\n\n\n\n\n\n\n\n\n\nJul 19, 2025\n\n\nCaio dos Santos\n\n\n\n\n\n\n\n\n\n\n\n\nProcessing as-applied and as-planted data in on-farm trials\n\n\n\n\n\n\npacu\n\nyield monitor\n\n\n\n\n\n\n\n\n\nJul 19, 2025\n\n\nCaio dos Santos\n\n\n\n\n\n\n\n\n\n\n\n\nSpecifying custom vegetation indices\n\n\n\n\n\n\npacu\n\nremote sensing\n\n\n\n\n\n\n\n\n\nMay 13, 2025\n\n\nCaio dos Santos\n\n\n\n\n\n\n\n\n\n\n\n\nProcessing data from an on-farm experiment\n\n\n\n\n\n\npacu\n\nyield monitor\n\n\n\n\n\n\n\n\n\nMar 13, 2025\n\n\nCaio dos Santos\n\n\n\n\n\n\n\n\n\n\n\n\nWorking with yield monitor data\n\n\n\n\n\n\npacu\n\nyield monitor\n\n\n\n\n\n\n\n\n\nMar 10, 2025\n\n\nCaio dos Santos\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2026-01-26_probabilities-and-distributions/index.html",
    "href": "posts/2026-01-26_probabilities-and-distributions/index.html",
    "title": "Probability and Distributions",
    "section": "",
    "text": "Before we introduce statistical distributions like the normal distribution, we need a way to talk about uncertainty.\nIn agriculture and biological systems:\n\nOutcomes vary\nMeasurements are never identical\nWe rarely know exact future values\n\nProbability gives us a language to describe how likely different outcomes are. I like to think of probability as a way of counting the number of different ways a given event can happen within a system.\nAn example would be, in a given corn field in a given year:\n\nHow likely are we to measure an average yield throughout the field above 180 bu/ac?\n\nThis question can be stated again as:\n\nHow many scenarios out of all possible scenarios for this field can the average be above 180 bu/ac?\n\nTo answer this question, we need to understand how yield values vary and how frequently different values occur. We are going to talk about this soon! First, let me do a brief detour to explain some important concepts.\n\n\n\n\n\nTo think of probability as a way of counting the occurrence of a given scenario within all possible scenarios, I believe it is useful to think of a case in which there is a limit to the number of scenarios: a deck of cards!\n\nBy this definition, we can think of probability of event \\(x\\) happening as:\n\\[ Pr(x) = \\frac{n}{N}\\]\nUsing this framework, let’s think of the probability of drawing an ace from an ordinary deck of 52 playing cards:\nSince there are 4 aces (\\(n=4\\)), among the 52 cards (\\(N=52\\)), the probability of drawing an ace is \\(4/52\\) or \\(1/13\\).\n\n\n\nProbability does not tell us what will happen in a single case; it describes patterns across many possible cases.\n\n\nIf we’re thinking of counting ways that an event could happen among all possible events, the lower limit for how probable an event is would for this event to simply never happen among all scenarios. This would result in \\(n=0\\). As a result, regardless of the value of \\(N\\), we have:\n\\[Pr(x) = \\frac{0}{N} = 0\\]\nSimilarly, for the upper bound, the most this event could happen is in every possible scenario. Thus, \\(n=N\\). This results in:\n\\[Pr(x) = \\frac{N}{N} = 1\\]\n\n\n\nThe same way we are counting the number of times an event could happen among all scenarios (like our ace among all 52 cards), we can think of the number of times all other events could happen, except for this one. For example, what is the probability of not drawing an ace?\nThere are 48 cards that do not represent an ace, therefore, the probability is \\(48/52\\) or \\(12/13\\).\nSince when you draw a card you are going to draw either an ace or any other card, the probability of drawing an ace (\\(1/13\\)) or any other card (\\(12/13\\)) must add up to 1. Therefore:\n\\[Pr(not~x) = 1 - Pr(x)\\]\nThis idea will be especially useful later when we talk about probabilities above or below a threshold, such as yield exceeding a certain value.\n\n\n\n\nWe can visualize the distribution of the probability values according to the cards in the graph below. Assuming this is an ordinary deck of cards, all cards have the same probability of being draw. That’s why the graph showing the probability is so boring!\nIf we sum the area of all of these bars, they should add up to 1! That’s a fundamental concept of probability distributions that we will use on more complex systems but that can be easily visualized here. If you are familiar with calculus, would this be similar to computing the area under the curve?\n\n\n\n\n\n\n\n\n\nThe mathematical formula representing this system is:\n\\[Pr(x) = 1/13,~for~x=ace,2,3,\\ldots,king\\]\n\n\n\n\nOk, so natural systems, such as agricultural fields, are not as simple as a deck of cards, right? I believe that’s a good thing, otherwise we’d all be out of a job! In agronomic systems, we will often use more complex probability distributions to model the randomness of data, but the concepts we have just learned are going to remain the same!\n\n\nOne commonly used probability distribution in agriculture is the normal distribution. It describes situations where values tend to cluster around an average, with fewer observations far from the mean. Take a look at the graph below.\nIn the card example, outcomes were discrete and countable. However, yield is a continuous variable, and it can take on many possible values within a range. For continuous variables, probabilities are described using probability density rather than simple counts.\n\n\n\n\n\n\n\n\n\nThe height of the curve at any point is not a probability by itself. Probabilities come from the area under the curve over a range of values. In the case of the deck of cards, adding up the area of the bars was equal to one. Here, that’s also true. Except that, for continuous variables, to compute the area under the curve, we need to integrate over \\(X\\). We will not cover this more advanced calculus tasks in this class, but I wanted you to have an intuition for it.\nTherefore, the red shaded area in the figure below has an area equal to 1. This means that the probability of \\(x\\) assuming any value possible is 1. In the case of the deck of cards, it would be the equivalent of asking “What is the probability of the card I drew being a card?”. Sounds silly, I know!"
  },
  {
    "objectID": "posts/2026-01-26_probabilities-and-distributions/index.html#why-do-we-care-about-probability",
    "href": "posts/2026-01-26_probabilities-and-distributions/index.html#why-do-we-care-about-probability",
    "title": "Probability and Distributions",
    "section": "",
    "text": "Before we introduce statistical distributions like the normal distribution, we need a way to talk about uncertainty.\nIn agriculture and biological systems:\n\nOutcomes vary\nMeasurements are never identical\nWe rarely know exact future values\n\nProbability gives us a language to describe how likely different outcomes are. I like to think of probability as a way of counting the number of different ways a given event can happen within a system.\nAn example would be, in a given corn field in a given year:\n\nHow likely are we to measure an average yield throughout the field above 180 bu/ac?\n\nThis question can be stated again as:\n\nHow many scenarios out of all possible scenarios for this field can the average be above 180 bu/ac?\n\nTo answer this question, we need to understand how yield values vary and how frequently different values occur. We are going to talk about this soon! First, let me do a brief detour to explain some important concepts."
  },
  {
    "objectID": "posts/2026-01-26_probabilities-and-distributions/index.html#a-brief-non-agronomic-example",
    "href": "posts/2026-01-26_probabilities-and-distributions/index.html#a-brief-non-agronomic-example",
    "title": "Probability and Distributions",
    "section": "",
    "text": "To think of probability as a way of counting the occurrence of a given scenario within all possible scenarios, I believe it is useful to think of a case in which there is a limit to the number of scenarios: a deck of cards!\n\nBy this definition, we can think of probability of event \\(x\\) happening as:\n\\[ Pr(x) = \\frac{n}{N}\\]\nUsing this framework, let’s think of the probability of drawing an ace from an ordinary deck of 52 playing cards:\nSince there are 4 aces (\\(n=4\\)), among the 52 cards (\\(N=52\\)), the probability of drawing an ace is \\(4/52\\) or \\(1/13\\).\n\n\n\nProbability does not tell us what will happen in a single case; it describes patterns across many possible cases.\n\n\nIf we’re thinking of counting ways that an event could happen among all possible events, the lower limit for how probable an event is would for this event to simply never happen among all scenarios. This would result in \\(n=0\\). As a result, regardless of the value of \\(N\\), we have:\n\\[Pr(x) = \\frac{0}{N} = 0\\]\nSimilarly, for the upper bound, the most this event could happen is in every possible scenario. Thus, \\(n=N\\). This results in:\n\\[Pr(x) = \\frac{N}{N} = 1\\]\n\n\n\nThe same way we are counting the number of times an event could happen among all scenarios (like our ace among all 52 cards), we can think of the number of times all other events could happen, except for this one. For example, what is the probability of not drawing an ace?\nThere are 48 cards that do not represent an ace, therefore, the probability is \\(48/52\\) or \\(12/13\\).\nSince when you draw a card you are going to draw either an ace or any other card, the probability of drawing an ace (\\(1/13\\)) or any other card (\\(12/13\\)) must add up to 1. Therefore:\n\\[Pr(not~x) = 1 - Pr(x)\\]\nThis idea will be especially useful later when we talk about probabilities above or below a threshold, such as yield exceeding a certain value.\n\n\n\n\nWe can visualize the distribution of the probability values according to the cards in the graph below. Assuming this is an ordinary deck of cards, all cards have the same probability of being draw. That’s why the graph showing the probability is so boring!\nIf we sum the area of all of these bars, they should add up to 1! That’s a fundamental concept of probability distributions that we will use on more complex systems but that can be easily visualized here. If you are familiar with calculus, would this be similar to computing the area under the curve?\n\n\n\n\n\n\n\n\n\nThe mathematical formula representing this system is:\n\\[Pr(x) = 1/13,~for~x=ace,2,3,\\ldots,king\\]"
  },
  {
    "objectID": "posts/2026-01-26_probabilities-and-distributions/index.html#back-to-agronomy",
    "href": "posts/2026-01-26_probabilities-and-distributions/index.html#back-to-agronomy",
    "title": "Probability and Distributions",
    "section": "",
    "text": "Ok, so natural systems, such as agricultural fields, are not as simple as a deck of cards, right? I believe that’s a good thing, otherwise we’d all be out of a job! In agronomic systems, we will often use more complex probability distributions to model the randomness of data, but the concepts we have just learned are going to remain the same!\n\n\nOne commonly used probability distribution in agriculture is the normal distribution. It describes situations where values tend to cluster around an average, with fewer observations far from the mean. Take a look at the graph below.\nIn the card example, outcomes were discrete and countable. However, yield is a continuous variable, and it can take on many possible values within a range. For continuous variables, probabilities are described using probability density rather than simple counts.\n\n\n\n\n\n\n\n\n\nThe height of the curve at any point is not a probability by itself. Probabilities come from the area under the curve over a range of values. In the case of the deck of cards, adding up the area of the bars was equal to one. Here, that’s also true. Except that, for continuous variables, to compute the area under the curve, we need to integrate over \\(X\\). We will not cover this more advanced calculus tasks in this class, but I wanted you to have an intuition for it.\nTherefore, the red shaded area in the figure below has an area equal to 1. This means that the probability of \\(x\\) assuming any value possible is 1. In the case of the deck of cards, it would be the equivalent of asking “What is the probability of the card I drew being a card?”. Sounds silly, I know!"
  },
  {
    "objectID": "posts/2026-01-26_probabilities-and-distributions/index.html#case-study",
    "href": "posts/2026-01-26_probabilities-and-distributions/index.html#case-study",
    "title": "Probability and Distributions",
    "section": "Case study",
    "text": "Case study\n\nSoybean yield data\nOk, so I spent some time now talking about the probabilities and distributions until now. Let’s take a look at how this applies to our case. We’ll load up some simulated yield data from a soybean field. Let’s take a look at the yield map:\n\n\n\n\n\n\n\n\n\nThis data contains 1038 observations and we can see that it varies between 64.52 and 96.54 bu/ac, averaging about 79.82 bu/ac. Not bad!\n\nlength(yield)\n\n[1] 1038\n\nsummary(yield)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  64.52   76.45   79.60   79.82   82.98   96.54 \n\n\nLet’s take a look at how our data is distributed across yield values. Yield values can present a bell shape distribution but can also be skewed towards one way or another. For this conceptual explanation, we will assume that the normal distribution model is a good representation of the randomness of yield data.\n\nhist(yield, xlab = 'Yield (bu/ac)')\n\n\n\n\n\n\n\n\n\n\nConnecting the histogram to the normal distribution\nOk, so let’s compute the mean (\\(\\mu\\)) and the standard deviation (\\(\\sigma\\)) of the yield data so that we can check that the normal distribution would be a good model to represent our yield data.\n\nmean(yield)\n\n[1] 79.82476\n\nsd(yield)\n\n[1] 5.12554\n\n\nUsing the mean and the standard deviation (and that ugly equation from before!!!), we can place the normal distribution model on top of our histogram. We can see that it’s a good fit. It’s not perfect because it’s a model but it can tell us many interesting things about the data, as we’ll see in the next steps.\nA side note, the normal distribution model tells us a lot about what to expect from the data in terms of which values will be more likely to be observed and which will be less likely. However, it does not tell us something like: Oh, the yield in this field will always be 79 bu/ac.\n\n\n\n\n\n\n\n\n\n\n\nComputing probabilities\nSomething that the normal distribution model allows us to do, is to check compute the probability of a given value falling within a range, right? Just like adding the area of the bars in the deck of cards example, if we integrate over \\(X\\) between two values, we can check the probability of observing a value of \\(X\\) within those ranges. Let’s check the probability of getting a value between 70 and 80 bushels!\nThe red shaded area is represents a probability of about 48.6% of the yield value falling between these bounds.\n\n\n\n\n\n\n\n\n\nWe can check that the normal distribution model is a good representation of our data by looking at the number of data points between these bounds as well. The code below shows that counting the data has a proportion of 51% of the data between those bounds. Not perfect but pretty close!\n\nN &lt;- length(yield)\nyield_values_within_bounds &lt;- yield[yield &gt;= 70 & yield &lt;= 80]\nn &lt;- length(yield_values_within_bounds)\nn / N\n\n[1] 0.5105973"
  },
  {
    "objectID": "posts/2026-01-26_probabilities-and-distributions/index.html#the-68-95-and-99-rule",
    "href": "posts/2026-01-26_probabilities-and-distributions/index.html#the-68-95-and-99-rule",
    "title": "Probability and Distributions",
    "section": "The 68%, 95%, and 99% rule",
    "text": "The 68%, 95%, and 99% rule\n\n68% probability or \\(1\\sigma\\)\nNow that we have standardized the normal distribution, we can think of it in terms of how many standard deviations from the mean a given value is. What is the probability of a value being within \\(1\\sigma\\) of the mean? Let’s compute is!\n\n\n\n\n\n\n\n\n\n\n\n95% Probability or \\(1.96\\sigma\\)\nOne of the most common hard-set thresholds in statistics is to compare means or treatments, or compute confidence intervals at a 5% tolerance. Have you heard of it? 95% of the area of the curve is within \\(1.96\\sigma\\).\n\n\n\n\n\n\n\n\n\n\n\n99% Probability or \\(2.58\\sigma\\)\nAt times, we might want to be more cautious about finding differences. For example, when we are trying to identify whether a herbicide might cause injury to the crop. This is a situation in which a wrong test might cost a lot of money to the producer or the company. In that case, we might want to make our standards a little more strict to identify differences between treatments. Therefore, we might be interested in which values would correspond to 99% of the probability. That value corresponds to \\(2.58\\sigma\\)."
  },
  {
    "objectID": "posts/2026-01-26_probabilities-and-distributions/index.html#looking-into-the-future",
    "href": "posts/2026-01-26_probabilities-and-distributions/index.html#looking-into-the-future",
    "title": "Probability and Distributions",
    "section": "Looking into the future",
    "text": "Looking into the future\nWe have just learned the origin of important numbers in population statistics. As we get further into this course, we will learn about other distributions, such as binomial and F, and the unique tests in which they are used. Even in those cases, some of these concepts will stay the same: identifying whether the observed values are likely to occur (happening within those 95% or 99% bounds) or if they are unusual values (happening within the remaning 5% or 1% of the distribution)."
  },
  {
    "objectID": "posts/2025-05-13_vegetation-indices/index.html",
    "href": "posts/2025-05-13_vegetation-indices/index.html",
    "title": "Specifying custom vegetation indices",
    "section": "",
    "text": "Part of the motivation for developing pacu was to facilitate the access to and the analysis of satellite data. Up until now, users could only use one of the six pre-specified vegetation indices within pa_compute_vi(). In an effort to make the package more comprehensive, we have included the option of specifying custom vegetation indices. This gives users the freedom to go beyond the predefined vegetation indices and tailor their analysis to their specific needs! Here, we will go through an example of how to download and process satellite data using pacu. Let’s get started!"
  },
  {
    "objectID": "posts/2025-05-13_vegetation-indices/index.html#introduction",
    "href": "posts/2025-05-13_vegetation-indices/index.html#introduction",
    "title": "Specifying custom vegetation indices",
    "section": "",
    "text": "Part of the motivation for developing pacu was to facilitate the access to and the analysis of satellite data. Up until now, users could only use one of the six pre-specified vegetation indices within pa_compute_vi(). In an effort to make the package more comprehensive, we have included the option of specifying custom vegetation indices. This gives users the freedom to go beyond the predefined vegetation indices and tailor their analysis to their specific needs! Here, we will go through an example of how to download and process satellite data using pacu. Let’s get started!"
  },
  {
    "objectID": "posts/2025-05-13_vegetation-indices/index.html#data-acquisition-and-processing",
    "href": "posts/2025-05-13_vegetation-indices/index.html#data-acquisition-and-processing",
    "title": "Specifying custom vegetation indices",
    "section": "Data acquisition and processing",
    "text": "Data acquisition and processing\nWe will use two libraries for this example, pacu and sf. In case you do not have them installed, you can install them using the following code chunk\n\ninstall.packages('sf')\n\n## we will install pacu from GitHub because of some newly added features\n## version 0.1.63\nremotes::install_github('cldossantos/pacu')\n\nLet’s load the libraries:\n\nlibrary(sf)\nlibrary(pacu)\n\nIn this example, we’ll focus on the Ada Hayden Heritage Park. I will set up the corners here so you do not have to download any files to be able to follow along.\n\ncorners &lt;- matrix( c(-93.639, 42.0758,\n                     -93.6214, 42.0621), \n                   ncol = 2,\n                   byrow = TRUE)\n\ncorners &lt;- st_multipoint(corners)\n\n## defining our area of interest\naoi &lt;- st_as_sf(st_as_sfc(st_bbox(corners)),\n                crs = 4326)\n\nWe can search for images of the park over a given period and filter them based on cloud coverage. Here, we look for images from May of 2024 and with a maximum cloud coverage of 10%.\nnote: there is a registration step required before you can download images from Copernicus Data Space, please read the vignette.\n\navailable.images &lt;- pa_browse_dataspace(aoi, \n                                        start.date = '2024-05-13',\n                                        end.date = '2024-05-19',\n                                        max.cloud.cover = 10)\n\nWe have found one image matching our search parameters:\n\navailable.images\n\nSearch parameters\nStart date: 2024-05-13 \nEnd date: 2024-05-19 \nMax. cloud cover: 10%\nCollection name:  SENTINEL-2 \n\nResults\nTotal:  1 \nOnline:  1 \n\n\nDownloading the image can take some time. On my machine, it took about 7 minutes. Additionally, the image is quite large and can take up a lot of space on the computer. Providing the aoi argument ensures that pacu will crop the downloaded image to the area of interest. This can save a lot of storage space when working with several images.\n\ndownloaded.images &lt;- pa_download_dataspace(available.images,\n                                           dir.path = './raw-data/',\n                                           aoi = aoi,\n                                           verbose = FALSE) ## suppressing the progressbar\n\nHere, we can take a look at the true color image. It is actually a really pretty lake!\n\nrgb &lt;- pa_get_rgb(downloaded.images,\n                  verbose = FALSE)\npa_plot(rgb)\n\n\n\n\n\n\n\n\nOne of the pre-built vegeation indices within pacu is the Normalized Difference Vegetation Index (NDVI). This VI is often used as an indicator of crop health but in this case, we can see that it also shows us the lake quite well.\n\nndvi &lt;- pa_compute_vi(downloaded.images,\n                      vi = 'ndvi',\n                      verbose = FALSE)\n\npa_plot(ndvi)"
  },
  {
    "objectID": "posts/2025-05-13_vegetation-indices/index.html#specifying-custom-vegetation-indices",
    "href": "posts/2025-05-13_vegetation-indices/index.html#specifying-custom-vegetation-indices",
    "title": "Specifying custom vegetation indices",
    "section": "Specifying custom vegetation indices",
    "text": "Specifying custom vegetation indices\nResearchers might be interested in using other vegetation indices to identify water bodies, for example, such as the Multi-Band Water Index. This can be done by specifying the mathematical relationship between the Sentinel-2 bands in the formula argument of pa_compute_vi().\nIt is important to note that there is a mismatch between the resolution of the bands involved in this computation- some are 10m and others are 20m. The package will recognize that mismatch and resample the finer resolution band to match the coarser resolution ones. This means that the resolution of the output raster is the same as the resolution of the coarsest band involved in the computation.\n\nmbwi &lt;- pa_compute_vi(downloaded.images,\n                      vi = 'other',\n                      formula = mbwi ~ (2 * B03 - B04 - B08 - B11 - B12),\n                      verbose = FALSE)\npa_plot(mbwi, palette = 'Blues') ## blue colors for water!"
  },
  {
    "objectID": "posts/2025-05-13_vegetation-indices/index.html#conclusion",
    "href": "posts/2025-05-13_vegetation-indices/index.html#conclusion",
    "title": "Specifying custom vegetation indices",
    "section": "Conclusion",
    "text": "Conclusion\nWe have seen the process of acquiring and processing satellite data from Sentinel-2, and a new feature within pacu that allows us to specify custom vegetation indices. This gives the user more power to define and explore different indices that might be useful in a different discipline. We’ll be back with more pacu news later!"
  },
  {
    "objectID": "posts/2024-12-16_central-park/index.html",
    "href": "posts/2024-12-16_central-park/index.html",
    "title": "Remote sensing of NYC Central Park",
    "section": "",
    "text": "I thought it would be interesting to look at how to retrieve remotely sensed data from Sentinel-2 using the pacu package. For this example, I decided to take a look at the Central Park in New York city. Although it is not an agricultural setting, it is public large vegetated area.\nThe framework to download, process, and visualize the data for an agricultural field would be nearly identical. The one big difference would be the geographical coordinates. These would have to point to the targeted agricultural field.\nFirst, we can start by loading the libraries we will need for this task.\nlibrary(pacu)\nlibrary(sf)\nIf you have not installed these libraries, you can do so by running\ninstall.packages(\"pacu\")\nNow, we can define our area of interest. In this case, we will define the Central Park as our targeted area.\ncentral.park &lt;- read_sf('./central-park.shp', quiet = TRUE)\nThe first step to retrieve Sentinel-2 data is to register with Copernicus Data Space. Please check the package vignettes -more specifically the satellite data vignette- for more information on registering. You can also check the help page for the function pa_initialize_dataspace().\n?pa_initialize_dataspace\nWe can browse the Data Space catalog and check how many images will meet our search parameters. In this case, I am searching for images covering the Central Park between May and October, with 20% or less cloud coverage.\nWe can see that there are a total of 21 images the meet our criteria.\navailable.images &lt;- pa_browse_dataspace(aoi = central.park,\n                                        start.date = '2023-05-01',\n                                        end.date = '2023-10-30',\n                                        max.cloud.cover = 20)\navailable.images\n\nSearch parameters\nStart date: 2023-05-01 \nEnd date: 2023-10-30 \nMax. cloud cover: 20%\nCollection name:  SENTINEL-2 \n\nResults\nTotal:  23 \nOnline:  23\nThe summary() function can be used to tell us how many images we have available for every month.\nsummary(available.images)\n\n------------------\nYear  Month  Count \n---   ---    ---   \n2023  5      6     \n2023  6      2     \n2023  7      4     \n2023  8      3     \n2023  9      4     \n2023  10     4     \n------------------\nTotal   23\nLet us take a look at an image from May, one from July, and one from October.\nps: I am setting verbose to FALSE from now on to suppress the progress bar.\ndownloaded.images &lt;- pa_download_dataspace(available.images[c(3, 11, 21), ],\n                      aoi = central.park,\n                      dir.path = '.',\n                      verbose = FALSE)\nWe can look at a true color image using the pa_get_rgb() function.\ntrue.color &lt;- pa_get_rgb(downloaded.images, \n                         verbose = FALSE)\npa_plot(true.color)\nAlternatively, we can take a look at vegetation indices, such as the Normalized Difference Vegetation Index (NDVI).\nndvi &lt;- pa_compute_vi(downloaded.images, \n                      vi = 'ndvi',\n                      aoi = central.park,\n                      check.clouds = TRUE,\n                      verbose = FALSE)\npa_plot(ndvi)\nWe cal also look at the Normalized Difference Red Edge (NDRE) index. We can see that the image is at a coarser resolution, when compared to the NDVI image. This is because the Red Edge band in Sentinel-2 is at a 20m resolution, while the bands involved in the NDVI computation are at a 10m resolution.\nndre &lt;- pa_compute_vi(downloaded.images, \n                      vi = 'ndre',\n                      aoi = central.park,\n                      check.clouds = TRUE,\n                      verbose = FALSE)\npa_plot(ndre)\nWe can also take a look at the timeseries plot of the median NDRE over Central Park in 2023.\nsumm &lt;- summary(ndre, \n                by = central.park,\n                fun = function(x) median(x, na.rm = TRUE))\npa_plot(summ, plot.type = 'timeseries')"
  },
  {
    "objectID": "posts/2024-12-16_central-park/index.html#conclusion",
    "href": "posts/2024-12-16_central-park/index.html#conclusion",
    "title": "Remote sensing of NYC Central Park",
    "section": "Conclusion",
    "text": "Conclusion\nWe have seen how pacu can help us browse, download, and process satellite images for a non-agricultural setting. The workflow for an agricultural field would be nearly identical. We would only need to replace the area.of.interest."
  },
  {
    "objectID": "posts/2026-02-25_multiple-treatments/index.html",
    "href": "posts/2026-02-25_multiple-treatments/index.html",
    "title": "Multiple Treatment Trials",
    "section": "",
    "text": "Up to this point, we have focused on experiments with two treatments.\nBut most agronomic experiments involve more than two treatments:\n\nMultiple nitrogen rates\n\nSeveral hybrids\n\nSeveral fungicides\n\nDifferent seeding rates\n\nSo the question becomes:\n\nWhat changes when we move from two treatments to many?"
  },
  {
    "objectID": "posts/2026-02-25_multiple-treatments/index.html#experimental-layout",
    "href": "posts/2026-02-25_multiple-treatments/index.html#experimental-layout",
    "title": "Multiple Treatment Trials",
    "section": "Experimental Layout",
    "text": "Experimental Layout\nThis study was conducted with the 4 treatments mentioned previously and 8 replications, which brings the total number of experimental units to 32. In this case, all experimental units were randomly placed in the field. As the plot layout below shows."
  },
  {
    "objectID": "posts/2026-02-25_multiple-treatments/index.html#visualizing-the-data",
    "href": "posts/2026-02-25_multiple-treatments/index.html#visualizing-the-data",
    "title": "Multiple Treatment Trials",
    "section": "Visualizing the Data",
    "text": "Visualizing the Data\nLet’s take a look at the data from this trial. Like we’ve done in previous modules, let’s plot the individual observations as empty circles, and then represent the mean and standard error as filled triangles and error bars, respectively.\n\n\n\n\n\n\n\n\n\nWe can see that we have four sample means and their standard errors, each of them represents a different population that we want to make a statement about. Like we’ve seen in previous modules, each set of sample mean and standard deviation represents a population. These populations can be represented in the distribution plot below:"
  },
  {
    "objectID": "posts/2026-02-25_multiple-treatments/index.html#research-question",
    "href": "posts/2026-02-25_multiple-treatments/index.html#research-question",
    "title": "Multiple Treatment Trials",
    "section": "Research question:",
    "text": "Research question:\n\nDoes seed treatment affect corn yield?"
  },
  {
    "objectID": "posts/2026-02-25_multiple-treatments/index.html#hypotheses",
    "href": "posts/2026-02-25_multiple-treatments/index.html#hypotheses",
    "title": "Multiple Treatment Trials",
    "section": "Hypotheses",
    "text": "Hypotheses\nNull hypothesis:\n\\[H_0: \\mu_{control} = \\mu_{I}= \\mu_{F}= \\mu_{I + F}\\]\nAlternative hypothesis:\n\\[H_a: at~least~one~mean~is~different\\]\nNote that the alternative hypothesis does not tell us which of the means is different from the others. It simply states that at least one of them is. Figuring out which mean differs, in case we reject \\(H_0\\), is a separate step that we will explore in a future class."
  },
  {
    "objectID": "posts/2026-02-25_multiple-treatments/index.html#the-linear-additive-model",
    "href": "posts/2026-02-25_multiple-treatments/index.html#the-linear-additive-model",
    "title": "Multiple Treatment Trials",
    "section": "The Linear Additive Model",
    "text": "The Linear Additive Model\nThe linear additive model is the same as before, just with more treatments:\n\\[Y_{ij} = \\mu + \\tau_i + \\epsilon_{ij}\\]\nWhere \\(i\\) indexes the treatment (control, insecticide only, fungicide only, insecticide + fungicide), and \\(j\\) indexes the observation for that treatment (replication).\nWhere:\n\\(Y_{ij}\\) = observed yield\n\\(\\mu\\) = overall mean yield\n\\(\\tau_i\\) = treatment effect\n\\(\\varepsilon_{ij}\\) = random error\nSince the linear additive model decomposes the population means into an overall mean (\\(\\mu\\)) and treatment effects (\\(\\tau_i\\)), our hypotheses can be restated as:\n\\[H_0: \\tau_{control} = \\tau_{I}= \\tau_{F}= \\tau_{I + F} = 0\\]\n\\[H_a: at~least~one~\\tau_i \\neq 0\\]\nThis leads to an important question:\n\nHow do we test this hypothesis?"
  },
  {
    "objectID": "posts/2026-02-25_multiple-treatments/index.html#multiple-t-tests",
    "href": "posts/2026-02-25_multiple-treatments/index.html#multiple-t-tests",
    "title": "Multiple Treatment Trials",
    "section": "Multiple \\(t\\)-tests",
    "text": "Multiple \\(t\\)-tests\nLet’s think about what comparing multiple populations with \\(t\\)-tests means.\n\nError rate\n\\(\\alpha\\) controls the error rate per test, which means that, as the number of tests grows, so does the probability that we will identify false positives in comparisons.\nThe table below shows the probability of finding at least one false positive effect (Type I Error) by the number of comparisons we make for two \\(\\alpha\\) values.\n\n\n\nNumber of tests\n\\(\\alpha=0.05\\)\n\\(\\alpha=0.01\\)\n\n\n\n\n1\n0.05\n0.01\n\n\n3\n0.14\n0.030\n\n\n6\n0.27\n0.06\n\n\n10\n0.40\n0.1\n\n\n45\n0.90\n0.36\n\n\n\nSome observations about this table:\n\nLower \\(\\alpha\\) values can help us control this experiment-wise error rate. However, remember the trade-off between \\(\\alpha\\) and power to identify differences?\nLowering \\(\\alpha\\) too much might hurt our ability to identify differences unless they’re large.\nAt 45 comparisons, we are almost guaranteed to make a mistake.\n\nLooking at these numbers, you might be asking how often do we make 45 comparisons?\n\n\nNumber of comparisons\nLet’s explore the relationship between the number of treatments and the number of comparisons in a trial.\n\n2 treatments\nIf we are comparing treatments A and B, the means we might think about are \\(\\mu_A\\) and \\(\\mu_B\\).\n\n\\(\\mu_A = \\mu_B\\)\n\n\n\n3 Treatments\nA, B, and C\nWe run the following comparisons:\n\n\\(\\mu_A = \\mu_B\\)\n\n\\(\\mu_B = \\mu_C\\)\n\n\\(\\mu_A = \\mu_C\\)\n\n\n\nVisualizing this relationship\nThe number of comparisons can be computed as \\(K\n\\times (K - 1)/2\\) and can be visualized below:\n\n\n\n\n\n\n\n\n\nIf we ran all pairwise t-tests, we would inflate our Type I error rate. Instead, we need a different approach. In this context, the Analysis of Variance (ANOVA) emerges as a solution."
  },
  {
    "objectID": "posts/2026-02-25_multiple-treatments/index.html#setting-up-the-anova-table",
    "href": "posts/2026-02-25_multiple-treatments/index.html#setting-up-the-anova-table",
    "title": "Multiple Treatment Trials",
    "section": "Setting up the ANOVA Table",
    "text": "Setting up the ANOVA Table\nGreat! Now we have all the effects we need to compute the \\(F\\)-statistic!\nI will set up a table for us to keep track of these numbers and we will populate this table as we go:\n\n\n\nSource of Variation\nSS\nDF\nMSE\nF\n\n\n\n\nTreatment\n\n\n\n\n\n\nResiduals (Error)\n\n\n\n\n\n\nTotal"
  },
  {
    "objectID": "posts/2026-02-25_multiple-treatments/index.html#sums-of-squares",
    "href": "posts/2026-02-25_multiple-treatments/index.html#sums-of-squares",
    "title": "Multiple Treatment Trials",
    "section": "Sums of Squares",
    "text": "Sums of Squares\nLet’s compute the Sums of Squares for all three rows\n\nSS_treatment &lt;- sum(seed_trial_eff$tau ^ 2) ## Treatment\nSS_error &lt;- sum(seed_trial_eff$epsilon ^ 2) ## Error\nSS_total &lt;- sum((seed_trial_eff$yield - seed_trial_eff$mu)^2) ## Total\n\nSS_treatment\n\n[1] 4439.003\n\nSS_error\n\n[1] 1781.786\n\nSS_total\n\n[1] 6220.788\n\n\nNow, let’s add these values to our table:\n\n\n\nSource of Variation\nSS\nDF\nMSE\nF\n\n\n\n\nTreatment\n4439\n\n\n\n\n\nResiduals (Error)\n1782\n\n\n\n\n\nTotal\n6220\n\n\n\n\n\n\nGreat! Let’s continue populating our table. Next, let’s compute the degrees of freedom!"
  },
  {
    "objectID": "posts/2026-02-25_multiple-treatments/index.html#degrees-of-freedom",
    "href": "posts/2026-02-25_multiple-treatments/index.html#degrees-of-freedom",
    "title": "Multiple Treatment Trials",
    "section": "Degrees of Freedom",
    "text": "Degrees of Freedom\nWe have a total of 32 observations, and we are estimating 4 means (one for each treatment)\nWe can compute the total number of degrees of freedom as:\n\\(DF_{total}\\) = 32 - 1 = 31\nThe degrees of freedom for the treatment can be computed as \\(K - 1\\), where K is the number of means we are estimating.\n\\(DF_{treatment}\\) = 4 - 1 = 3\nThe degrees of freedom for the error, is simply the difference between the total degrees of freedom, and the degrees of freedom taken by the treatment:\n\\(DF_{error}\\) = 31 - 3 = 28\nOur table now becomes:\n\n\n\nSource of Variation\nSS\nDF\nMSE\nF\n\n\n\n\nTreatment\n4439\n3\n\n\n\n\nResiduals (Error)\n1782\n28\n\n\n\n\nTotal\n6220\n31"
  },
  {
    "objectID": "posts/2026-02-25_multiple-treatments/index.html#mean-square-error",
    "href": "posts/2026-02-25_multiple-treatments/index.html#mean-square-error",
    "title": "Multiple Treatment Trials",
    "section": "Mean Square Error",
    "text": "Mean Square Error\nNext, we need to take the ratio between the SS and DF columns. Remember, this will give us an estimate for the variance of each effect. This estimate is called Mean Square Error (MSE).\n\nMS_treatment &lt;- SS_treatment/3 # MSE Treatment\nMS_error &lt;- SS_error/28 # MSE Residuals\n\nMS_treatment\n\n[1] 1479.668\n\nMS_error\n\n[1] 63.6352\n\n\n\n\n\nSource of Variation\nSS\nDF\nMSE\nF\n\n\n\n\nTreatment\n4439\n3\n1479.7\n\n\n\nResiduals (Error)\n1782\n28\n63.6\n\n\n\nTotal\n6220\n31"
  },
  {
    "objectID": "posts/2026-02-25_multiple-treatments/index.html#computing-the-f-statistic",
    "href": "posts/2026-02-25_multiple-treatments/index.html#computing-the-f-statistic",
    "title": "Multiple Treatment Trials",
    "section": "Computing the \\(F\\)-statistic",
    "text": "Computing the \\(F\\)-statistic\nNow, since the \\(F\\)-statistic is computed as the ratio between the treatment and error variances, and we are estimating them using the MSE, \\(F\\) can be computed as follows:\n\\[F = \\frac{\\sigma^2_{treatment}}{\\sigma^2_{error}} = \\frac{MSE_{treatment}}{MSE_{error}}\\]\n\nMS_treatment / MS_error\n\n[1] 23.25234\n\n\nIf treatments truly do not differ, both MS terms estimate the same variance, and F should be close to 1. An F-value of 23 means the treatment variance is 23 times larger than the background noise.\nAlright! This concludes our ANOVA table!!\n\n\n\nSource of Variation\nSS\nDF\nMSE\nF\n\n\n\n\nTreatment\n4439\n3\n1479.7\n23.25\n\n\nResiduals (Error)\n1782\n28\n63.6\n\n\n\nTotal\n6220\n31"
  },
  {
    "objectID": "posts/2026-02-25_multiple-treatments/index.html#p-value",
    "href": "posts/2026-02-25_multiple-treatments/index.html#p-value",
    "title": "Multiple Treatment Trials",
    "section": "P-value",
    "text": "P-value\nNow, like we have done before, we have to compare the \\(F\\)-statistic value we found with the \\(F\\)-distribution and compute the probability of observing a more extreme value given that \\(H_0\\) is true.\nWe will use the fastGraph library for that once again:\n\nlibrary(fastGraph)\nshadeDist(xshade = 23.25,\n          ddist = 'df',\n          parm1 = 3,\n          parm2 = 28,\n          lower.tail = FALSE)\n\n\n\n\n\n\n\n\nThis low p-value would provide strong evidence for us to reject \\(H_0\\), indicating that at least one of the treatment means is different from the others."
  },
  {
    "objectID": "posts/2026-02-25_multiple-treatments/index.html#r-built-in-function",
    "href": "posts/2026-02-25_multiple-treatments/index.html#r-built-in-function",
    "title": "Multiple Treatment Trials",
    "section": "R built-in function",
    "text": "R built-in function\nLike before, R has built-in function to run ANOVAs. However, I think it is important for us to build an ANVOA table step-by-step at least once, so we understand what each piece of information represents.\nLet’s run the built-in function:\n\nmodel1 &lt;- aov(yield ~ trt, data = trial)\nsummary(model1)\n\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ntrt          3   4439  1479.7   23.25 9.28e-08 ***\nResiduals   28   1782    63.6                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "posts/2025-03-13_on-farm-experiment/index.html",
    "href": "posts/2025-03-13_on-farm-experiment/index.html",
    "title": "Processing data from an on-farm experiment",
    "section": "",
    "text": "In a previous post, I have mentioned that pacu provided support for processing data coming from on-farm trials, as well as production fields. In this post, I want to explore and showcase this functionality a little more in depth. The idea is to provide an example of processing these data and make a few considerations that can greatly impact the end result.\nWe will look at simulated data from a small on-farm trial. This is made up data and I simulated a relationship between corn yield and nitrogen rate that followed a linear plateau relationship like the image below. The simulated relationship presented an intercept = 7000, slope = 30, and a breakpoint = 180. Let’s process this data and see if we can recover this relationship. You can download the data here."
  },
  {
    "objectID": "posts/2025-03-13_on-farm-experiment/index.html#introduction",
    "href": "posts/2025-03-13_on-farm-experiment/index.html#introduction",
    "title": "Processing data from an on-farm experiment",
    "section": "",
    "text": "In a previous post, I have mentioned that pacu provided support for processing data coming from on-farm trials, as well as production fields. In this post, I want to explore and showcase this functionality a little more in depth. The idea is to provide an example of processing these data and make a few considerations that can greatly impact the end result.\nWe will look at simulated data from a small on-farm trial. This is made up data and I simulated a relationship between corn yield and nitrogen rate that followed a linear plateau relationship like the image below. The simulated relationship presented an intercept = 7000, slope = 30, and a breakpoint = 180. Let’s process this data and see if we can recover this relationship. You can download the data here."
  },
  {
    "objectID": "posts/2025-03-13_on-farm-experiment/index.html#working-with-the-data",
    "href": "posts/2025-03-13_on-farm-experiment/index.html#working-with-the-data",
    "title": "Processing data from an on-farm experiment",
    "section": "Working with the data",
    "text": "Working with the data\nLoading the necessary packages\n\nlibrary(pacu)\nlibrary(sf)\nlibrary(nlraa)\nlibrary(nlme)\n\nHere, we will import the data sets into R. We will use two data sets for this exercise. The first contains made up raw yield data that represents data coming from an on-farm trial. The second contains an example of nitrogen rates applied to each experimental unit.\n\nraw.yield &lt;- read_sf('./raw-data/example-raw-data.shp',\n                     quiet = TRUE)\n\ntrial.design &lt;- read_sf('./raw-data/example-trial-design.shp',\n                     quiet = TRUE)\n\nLets take a look at how these two data sets line up in space. In this example, the points represent the yield monitor readings and the red rectangles represent the experimental units. We can see that, in this example, we had about 4 combine passes per experimental unit.\n\nplot(st_geometry(raw.yield), pch = 1, cex = 0.3)\nplot(st_geometry(trial.design), border = 'red', add = TRUE)\n\n\n\n\n\n\n\n\nAnother piece of information that can be extracted from the trial.design data set is the amount of nitrogen applied to each experimental unit in this example.\n\nplot(trial.design[\"nrate\"], main = 'Nitrogen rate (kg/ha)')\n\n\n\n\n\n\n\n\nWe can take a look at the raw yield data to see the kind of data we are dealing with. We can see that there is a lot of variability in the yield data, with it ranging from \\(\\approx 200\\) to \\(\\approx 12000\\) kg/ha. Some of this variability comes from the treatment effect but there’s a part of it that is just random variability. The challenge lies in identifying the treatment effect.\n\nboxplot(raw.yield$yld_kgh,\n        ylab = 'Yield (kg/ha)')\n\n\n\n\n\n\n\nplot(raw.yield[\"yld_kgh\"],\n     pch = 16,\n     main = 'Yield (kg/ha)',\n     breaks = 'quantile',\n     reset = FALSE)\nplot(st_geometry(trial.design),\n     add = TRUE)"
  },
  {
    "objectID": "posts/2025-03-13_on-farm-experiment/index.html#cleaning-based-on-standard-deviation",
    "href": "posts/2025-03-13_on-farm-experiment/index.html#cleaning-based-on-standard-deviation",
    "title": "Processing data from an on-farm experiment",
    "section": "Cleaning based on standard deviation",
    "text": "Cleaning based on standard deviation\nSomething that is common to do, is to use empirical rules to remove outliers and clean some of the noise inherent to these type of data, let’s see the effect of that.\nA pretty common procedure is to clean anything outside of 2 or 3 standard deviations from the mean (you can read more about it here). Let us take a look at this procedure. I will isolate one experimental unit for us to take a closer look. The removed points are marked with a red “X”. For this experimental unit, anything that was smaller tha 5622 or greater than 8139 kg/ha was removed.\n\n## selecting only experimental unit 5\nto.keep &lt;- as.numeric(st_intersects(raw.yield, trial.design[5, ]))\none.eu &lt;- raw.yield[!is.na(to.keep), 'yld_kgh']\n\n## calculating the mean and sd\neu.mean &lt;- mean(one.eu[['yld_kgh']])\neu.sd &lt;- sd(one.eu[['yld_kgh']])\n\n## defining upper and lower boundaries and identifying which\n## data points to remove\nupper.boundary &lt;- eu.mean + 2 * eu.sd\nlower.boundary &lt;- eu.mean - 2 * eu.sd\nto.remove &lt;- (one.eu$yld_kgh &lt; lower.boundary | \n                one.eu$yld_kgh &gt; upper.boundary)\n\n## showing which points were removed\nplot(one.eu, reset = FALSE,\n     main = 'Yield (kg/ha)',\n     pch = 16)\nplot(st_geometry(one.eu)[to.remove],\n     cex = 2,\n     col = 'red',\n     pch = 'x', \n     add = TRUE)\n\n\n\n\n\n\n\n\nWe can now apply this same methodology to all experimental units and see that, in total, we will remove 60 points from this data set.\n\nraw.yield$eu &lt;- as.numeric(st_intersects(raw.yield, trial.design))\nraw.yield &lt;- raw.yield[order(raw.yield$eu), ]\nto.remove &lt;- ave(raw.yield$yld_kgh, \n                 raw.yield$eu,\n                 FUN = function(x){\n                   eu.mean &lt;- mean(x)\n                   eu.sd &lt;- sd(x)\n                   upper.boundary &lt;- eu.mean + 2 * eu.sd\n                   lower.boundary &lt;- eu.mean - 2 * eu.sd\n                    (x &lt; lower.boundary | x &gt; upper.boundary)\n                 })\nto.remove &lt;- as.logical(to.remove)\n\nplot(raw.yield['yld_kgh'], \n     main = 'Yield (kg/ha)',\n     reset = FALSE,\n     pch = 16)\nplot(st_geometry(raw.yield)[to.remove],\n     col = 'red',\n     pch = 'x', \n     add = TRUE)\n\n\n\n\n\n\n\n\nNow, let us remove these data points, and average the yield observations within each experimental unit. We can see that our estimates of the model parameters are not quite the same ones that we simulated. In addition, the variance of the parameter estimates is pretty large. This means that we are not very certain of these values.\n\nyield.filtered.sd &lt;- raw.yield[!to.remove, ]\nmean.yield.sd &lt;- aggregate(yield.filtered.sd['yld_kgh'],\n                           trial.design,\n                           FUN = mean)\nmean.yield.sd &lt;- st_join(mean.yield.sd, trial.design, join = st_equals)\n\n\nfit1 &lt;- nls(yld_kgh ~ SSlinp(nrate, a, b, xs),\n            data = mean.yield.sd)\n# estimates\ncoef(fit1)\n\n         a          b         xs \n6814.09790   28.01518  168.74310 \n\n# variances\ndiag(vcov(fit1))\n\n           a            b           xs \n28833.979455     3.075624    71.175162 \n\n## Visualizing the data\n\npreds &lt;- data.frame(nrate = 0:300)\npreds &lt;- cbind(preds,  predict_nls(fit1,\n                                   interval = 'conf',\n                                   newdata = preds))\n\nplot(mean.yield.sd$nrate, mean.yield.sd$yld_kgh, \n     xlab = 'Nitrogen rate (kg/ha)',\n     ylab = 'Yield (kg/ha)')\npolygon(x = c(preds$nrate, rev(preds$nrate)),\n        y = c(preds$Q2.5, rev(preds$Q97.5) ),\n        border = 'steelblue', lty = 2) \nlines(preds$nrate, preds$Estimate, \n      col = 'blue')\nlegend('bottomright',\n       lty = 1:2,\n       legend = c('Estimate', 'CI'),\n       col = c('blue', 'steelblue'))"
  },
  {
    "objectID": "posts/2025-03-13_on-farm-experiment/index.html#adding-a-buffer-to-the-experimental-units",
    "href": "posts/2025-03-13_on-farm-experiment/index.html#adding-a-buffer-to-the-experimental-units",
    "title": "Processing data from an on-farm experiment",
    "section": "Adding a buffer to the experimental units",
    "text": "Adding a buffer to the experimental units\nAnother empirical cleaning method that is commonly used is to add a buffer to the experimental units. This in meant to remove some of the border effect or the transition between experimental units. However, adding a buffer needs to be done with caution. You want your buffer to be big enough to remove some of these potentially problematic observations, but you do not want your buffer to remove so many points that you will end up estimating the mean with few points. This would increase the uncertainty of your estimate. Let’s take a look at different buffer sizes:\n\nbuffers &lt;- c(1, 2, 5, 10)\ncols &lt;- hcl.colors(4, palette = 'Temps')\nplot(st_geometry(raw.yield), cex = 0.5)\nfor (i in 1:length(buffers)){\n  buffered.exp.units &lt;- st_as_sf(st_buffer(trial.design, -buffers[i]))\n  plot(st_geometry(buffered.exp.units), border = cols[i], add = TRUE)\n}\nlegend('topleft', \n       fill = cols,\n       legend = buffers,\n       title = 'Buffer size (m)')\n\n\n\n\n\n\n\n\nIt seems that a buffer size of about 5 meters is what we want for this example. Let’s go with that and see which observations will be removed from the data set:\n\nbuffered.exp.units &lt;- st_as_sf(st_buffer(trial.design, -5))\nraw.yield$eu &lt;- as.numeric(st_intersects(raw.yield, buffered.exp.units))\nraw.yield &lt;- raw.yield[order(raw.yield$eu), ]\nto.remove &lt;- ave(raw.yield$yld_kgh, \n                 raw.yield$eu,\n                 FUN = function(x){\n                   eu.mean &lt;- mean(x)\n                   eu.sd &lt;- sd(x)\n                   upper.boundary &lt;- eu.mean + 2 * eu.sd\n                   lower.boundary &lt;- eu.mean - 2 * eu.sd\n                    (x &lt; lower.boundary | x &gt; upper.boundary)\n                 })\n\nto.remove &lt;- as.logical(to.remove)\n\nplot(raw.yield['yld_kgh'], \n     main = 'Yield (kg/ha)',\n     reset = FALSE,\n     pch = 16)\nplot(st_geometry(raw.yield)[to.remove],\n     col = 'red',\n     pch = 'x', \n     add = TRUE)\n\n\n\n\n\n\n\n\nNow, let us remove these data points, and average the yield observations within each experimental unit. We can see that our estimates of the model parameters are a little closer to the true values but still not quite there. Also, the variance has decreased quite a bit but let’s see if we can increase the precision of our estimates!\n\nyield.filtered.buffer &lt;- raw.yield[!to.remove, ]\nmean.yield.buffer &lt;- aggregate(yield.filtered.buffer['yld_kgh'],\n                           trial.design,\n                           FUN = mean)\nmean.yield.buffer &lt;- st_join(mean.yield.buffer, trial.design, join = st_equals)\n\n\nfit2 &lt;- nls(yld_kgh ~ SSlinp(nrate, a, b, xs),\n            data = mean.yield.buffer)\n## estimates\ncoef(fit2)\n\n        a         b        xs \n6659.5802   30.3704  172.9306 \n\n## variances\ndiag(vcov(fit2))\n\n          a           b          xs \n6649.190326    0.709247   14.583390 \n\n## Visualizing the data\n\npreds &lt;- data.frame(nrate = 0:300)\npreds &lt;- cbind(preds,  predict_nls(fit2,\n                                   interval = 'conf',\n                                   newdata = preds))\n\nplot(mean.yield.buffer$nrate, \n     mean.yield.buffer$yld_kgh, \n     xlab = 'Nitrogen rate (kg/ha)',\n     ylab = 'Yield (kg/ha)')\npolygon(x = c(preds$nrate, rev(preds$nrate)),\n        y = c(preds$Q2.5, rev(preds$Q97.5) ),\n        border = 'steelblue', lty = 2) \nlines(preds$nrate, preds$Estimate, \n      col = 'blue')\n\nlegend('bottomright',\n       lty = 1:2,\n       legend = c('Estimate', 'CI'),\n       col = c('blue', 'steelblue'))\n\n\n\n\n\n\n\n\nWe get a little closer to the true value with every layer of processing that we include in this exercise. However, these layers are empirical and somewhat arbitrary. By adding a buffer zone, we are looking to remove points that have an influence from the adjacent experimental units. This can be done using the ritas algorithm within pacu."
  },
  {
    "objectID": "posts/2025-03-13_on-farm-experiment/index.html#using-pa_yield",
    "href": "posts/2025-03-13_on-farm-experiment/index.html#using-pa_yield",
    "title": "Processing data from an on-farm experiment",
    "section": "Using pa_yield",
    "text": "Using pa_yield\nThe pa_yield function has built-in capabilities to automate these processes without the need for these empirical rules. For instance, by setting the argument remove.crossed.polygons to TRUE, we remove data that could be influenced by adjacent experimental units. You can read more about the ritas algorithm here.\nSo we can visualize these steps, I will set the option steps to TRUE. This is a new addition to the package and is not yet available on CRAN. Please install the package from GitHub to be able to use this.\n\nyld3 &lt;- pa_yield(raw.yield,\n                 data.columns = c(mass = 'mass_g',\n                                  interval = 'intrvl_',\n                                  distance = 'dstnc_f',\n                                  width = 'swth_ft',\n                                  angle = 'angl_dg',\n                                  moisture = 'moistur'),\n                 grid = trial.design,\n                 steps = TRUE,\n                 algorithm = 'ritas',\n                 unit.system = 'metric',\n                 verbose = FALSE,\n                 remove.crossed.polygons = TRUE,\n                 cores = 6)\n\nyld4 &lt;- st_join(yld3$yield, trial.design, join = st_equals)\nyld4$yield_kgh &lt;- yld4$yield * 1000 ## converting from t/ha\n                                    ## to kg/ha    \nfit3 &lt;- nls(yield_kgh ~ SSlinp(nrate, a, b, xs),\n            data = yld4)\n\n## estimates\ncoef(fit3)\n\n         a          b         xs \n6997.17524   30.40087  176.09137 \n\n## variances\ndiag(vcov(fit3))\n\n           a            b           xs \n1401.4136937    0.1494841    3.1692490 \n\n## Visualizing the data\n\npreds &lt;- data.frame(nrate = 0:300)\npreds &lt;- cbind(preds,  predict_nls(fit3,\n                                   interval = 'conf',\n                                   newdata = preds))\n\nplot(yld4$nrate, \n     yld4$yield_kgh, \n     xlab = 'Nitrogen rate (kg/ha)',\n     ylab = 'Yield (kg/ha)')\npolygon(x = c(preds$nrate, rev(preds$nrate)),\n        y = c(preds$Q2.5, rev(preds$Q97.5) ),\n        border = 'steelblue', lty = 2) \nlines(preds$nrate, preds$Estimate, \n      col = 'blue')\n\n\nlegend('bottomright',\n       lty = 1:2,\n       legend = c('Estimate', 'CI'),\n       col = c('blue', 'steelblue'))\n\n\n\n\n\n\n\n\nWe can see that the pa_yield() function was able to produce more precise estimates of the model parameters. In part, this is due to the ritas algorithm recreating the destructive harvest process and being able to track which harvest polygons have crossed between different experimental units. We can see that in the plot below that demonstrates which polygons were removed:\n\nwith(yld3$steps, {\n  plot(adjusted.polygons, border = 'red')\n  plot(cleaned.polygons, add = TRUE)\n  plot(grid, add = TRUE, border = 'blue')\n  legend('topleft',\n         fill = rep(NA, 3),\n         border = c('black', 'red', 'blue'),\n         legend = c('harvest polygons', \n                    'removed polygons',\n                    'experimental units'))\n})"
  },
  {
    "objectID": "posts/2025-03-13_on-farm-experiment/index.html#conclusion",
    "href": "posts/2025-03-13_on-farm-experiment/index.html#conclusion",
    "title": "Processing data from an on-farm experiment",
    "section": "Conclusion",
    "text": "Conclusion\nIn this exercise, we have seen how different decisions about data processing can affect the estimates we get from the yield monitor data. We have also seen how we can use the pa_yield() function to process the yield data coming from agronomic trials. The differences in the precision of the estimates are really important when we want to estimate confidence intervals or investigate whether a certain covariate has an effect. For instance, let’s say that, in addition to nitrogen rates, we also had nitrogen source. More precise estimates would increase the power of our analysis to find differences."
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Software\n\n\npacu: Precision Agriculture Computational Utilities, 2024  go to repository\n\n\nSoyStage - Online decision support tool for the Midsouthern U.S., 2019.  go to website\n\n\n\n\n\nPeer-reviewed publications\n\n2025\n\nPinto, J.G.C., Balboa, G., Mueller, N., Slater, G., Frels, K., dos Santos, C.L., Miguez, F.E., Lollato, R., & Puntel, L.A. (2025). Evaluation of APSIM Next Generation for simulating winter wheat growth, yield response to nitrogen, and nitrogen dynamics. Frontiers in Agronomy, 7.  go to article\n\n\nPessotto, M.V., Roberts, T.L., dos Santos, C.L., Hoegenauer, K., Bertucci, M., Ross, J., & Savin, M. (2025). Use of growing degree days to predict aboveground biomass and total nitrogen accumulation of winter cover crops. Agrosys- tems, Geosciences & Environment, 8, 4.  go to article\n\n\ndos Santos, Caio L. & Miguez, F. E. (2025). A comparative study of yield monitor data processing methods for on-farm agronomic trials. Agronomy Journal, 117, e70168.  go to article\n\n\nCarvalho-Moore, P., Norsworthy, J., Porri, A., dos Santos, C.L., Barber, T., Sudhakar, S., Meiners, I., & Lerchl, J. (2025). Is glufosinate resitance in Palmer Amaranth spreading in Mississippi County, Arkansas? Weed Science, 73, e62.  go to article\n\n\n\n2024\n\ndos santos, C.L., & Miguez, F.E. (2024). PACU: Precision agriculture computational utilities. SoftwareX, 28, 101971.  go to article\n\n\n\n2023\n\nPessotto, M. V., Roberts, T.L., Bertucci, M., dos Santos, C., Ross, J., and Savin, M. (2023). Determining cardinal temperatures for eight cover crop species. Agrosystems, Geosciences & Environment, 6, e20393.  go to article\n\n\ndos Santos, C. L., Miguez, F. E., King, K. A., Ruiz, A., Sciarresi, C., Baum, M. E., Danalatos, G. J. N., Stellman, M., Wiley, E., Pico, L.O., Thies, A., Puntel, L. A., Topp, C. N., Trifunovic, S., Eudy, D., Mensah, C., Edwards, J. W., Schnable, P. S., Lamkey, K. R., … , and Archontoulis, S. V. (2023). Accelerated leaf appearance and flowering in maize after four decades of commercial breeding. Crop Science, 1–13.  go to article\n\n\n\n2022\n\nRuiz, A., Trifunovic, S., Eudy, D.M., Sciarresi, S. C., Baum, M., Danalatos, G.J.N., Elli, E.F., Kalogeropoulos,G., King, K., dos Santos, C.L., Thies, A., Pico, L.O., Castellano, M.J., Schnable, P.K., Topp, C., Graham, M., Lamkey, K.R., Vyn, T.J., and Archontoulis, S.V. (2023). Harvest Index has increased over the last 50 years of maize breeding. Field Crops Research, 300, 10900.  go to article\n\n\ndos Santos, C.L.; Abendroth, L.J.; Coulter, J.A.; Nafziger, E.D.; Suyker, A.; Yu, J.; Schnable, P.S.; Archontoulis, S.V. (2022). Maize Leaf Appearance Rates: A Synthesis From the United States Corn Belt. Frontiers in Plant Science, 13.  go to article\n\n\n\n2021\n\n\ndos Santos C.L., T.L. Roberts, and L.C. Purcell. (2021). Leaf Nitrogen Sufficiency Level Guidelines for Midseason Fertilization in Corn. Agronomy Journal, 113, 1974-1980.  go to article\n\n\n\n2020\n\ndos Santos, C.L., T.L. Roberts, L.C. Purcell. (2020). Canopy greenness as a midseason nitrogen management tool in corn production. Agronomy Journal. 112, 5279-5287.  go to article\n\n\n\n2019\n\ndos Santos, C.L., M. Salmerόn, and L.C. Purcell. (2019). Soybean phenology prediction tool for the Midsouth. Agricultural and Environmental Lettters, 4, 190036.  go to article\n\n\n\n2018\n\ndos Santos, C.L., A.F. De Borja Reis, P. Mazzafera, J.L. Favarin. (2018). Determination of the water potential threshold at which rice growth is impacted. Plants 7, 48.  go to article"
  },
  {
    "objectID": "posts/2026-02-02_sample-statistics/index.html",
    "href": "posts/2026-02-02_sample-statistics/index.html",
    "title": "Sample Statistics",
    "section": "",
    "text": "In the last two modules, we focused on populations and on how to summarize them when we are able to measure every individual. In that context, quantities like the mean and the standard deviation describe the entire population, because they are calculated using all available observations.\nIn agricultural science this is almost never possible, because the volume of fieldwork required to measure every single individual would simply be prohibitive to the work. If you have done field work before, can you imagine having to measure every single plant within an experimental unit? Instead, we rely on samples, right? This means that we collect from a subset of individuals and use those to learn about the population as a whole.\nWhen we work with samples, instead of the whole population, we no longer can quantify the population mean (\\(\\mu\\)) and standard deviation (\\(\\sigma\\)) with certainty. Instead, we need to estimate these parameters from the information we retrieved from the samples. Now, this raises a couple questions, right? For example:\n\nWas the sample representative of the population?\nIf we took a different random sample, would we get similar estimates?\nAnd how far might a sample mean be from the true population mean?\nShould we have taken more samples perhaps?\n\nIn other words, statistics computed from samples involve increased uncertainty. We rarely have complete confidence that a single sample mean perfectly represents the population mean.\nThis is where sampling distributions come in. Through replicated samples and examining how their means vary, we can describe the distribution of sample means around the population mean. This idea sits at the core of statistical inference: we use variability among samples to quantify how accurate our estimates are and how much uncertainty we should expect when making statements about a population."
  },
  {
    "objectID": "posts/2026-02-02_sample-statistics/index.html#one-sample",
    "href": "posts/2026-02-02_sample-statistics/index.html#one-sample",
    "title": "Sample Statistics",
    "section": "One sample",
    "text": "One sample\nLet’s say that you were short on resources and could only sample this field once. How variable could your sample mean be?\nTo establish an easy way to compare the next steps, let’s draw a red line representing the population mean (\\(\\mu\\)). Then, we can represent the sample mean (\\(\\bar{x}\\)) in blue, and the sampled points as black dots.\n\n\n\n\n\n\n\n\n\nBy chance, with one sample, we would end up with a sample average of 71.74 bu/ac. But, this is one time, right? Let’s say I had gone to that field in a different day and had sampled a different location. As we can see from the graph below, with one sample, I could have gotten an average of 89.95 bu/ac. This illustrates that when we have low sample sizes, there’s a lot of variability in our measurements. This means you’re getting two very different answers simply by because of the location within the field that you sampled."
  },
  {
    "objectID": "posts/2026-02-02_sample-statistics/index.html#ten-samples",
    "href": "posts/2026-02-02_sample-statistics/index.html#ten-samples",
    "title": "Sample Statistics",
    "section": "Ten samples",
    "text": "Ten samples\nOk, so let’s say you got some more resources to increase your sample size. Let’s see what happens with ten samples.\nWe can see that with 10 samples, we were able to get closer to the true mean on this iteration. Even though we had samples above and below \\(\\mu\\), on average, we are close.\n\n\n\n\n\n\n\n\n\nIf we had sampled ten times in other parts of the field, the result would be the graph below. We are still close to \\(\\mu\\) again. This shows that greater sample sizes will decrease the variability in the sample mean."
  },
  {
    "objectID": "posts/2026-02-02_sample-statistics/index.html#visualizing-the-relationship-between-sample-size-and-variability",
    "href": "posts/2026-02-02_sample-statistics/index.html#visualizing-the-relationship-between-sample-size-and-variability",
    "title": "Sample Statistics",
    "section": "Visualizing the relationship between sample size and variability",
    "text": "Visualizing the relationship between sample size and variability\nSo we can see how much the sample size can influence the variability of our sample mean, let’s do an exercise together. I will repeat the same procedure as before 10 times (10 iterations) and plot all of them in the same graph. The number on each panel represents the sample size.\nIn the graph below, you can see on the y-axis the iteration number and on the x-axis the yield value in bu/ac. Just like before, the red line still represents the population mean. The multiple blue lines now represent the sample mean for each iteration. As you can see, as the sample size increases, the sample mean lines cluster around the population mean. This shows this decrease in variability of the sample mean as a function of the increase in sample size."
  },
  {
    "objectID": "posts/2026-02-02_sample-statistics/index.html#standard-error-of-the-mean",
    "href": "posts/2026-02-02_sample-statistics/index.html#standard-error-of-the-mean",
    "title": "Sample Statistics",
    "section": "Standard error of the mean",
    "text": "Standard error of the mean\nThis decrease in variability as a function of an increase in sample size is well represented by a statistic called the standard error of the mean, which can be calculated as follows:\n\\[\\sigma_{\\bar{x}} = \\frac{\\sigma}{\\sqrt{n}}\\]"
  },
  {
    "objectID": "posts/2026-02-02_sample-statistics/index.html#central-limit-theorem",
    "href": "posts/2026-02-02_sample-statistics/index.html#central-limit-theorem",
    "title": "Sample Statistics",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\nOne of the most important theorems in statistics is the Central Limit Theorem (CLT), which states the following:\nThe distribution of the sample mean can be approximated as normal with mean \\(=\\mu\\) and variance \\(=\\frac{\\sigma^2}{n}\\) when \\(n\\) is large\nIn practice, this approximation is used when \\(n\n\\geq 30\\) regardless of the distribution of the population sampled. For smaller \\(n\\) this approximation can be questionable.\nYou may recognize that the variance of the sampling distribution is the square of the standard error of the mean.\n\nIllustrating this principle\nI thought you might appreciate seeing the Central Limit Theorem in action. In the yield monitor data example, the yield data was approximately normally distributed already, so it made sense that the sampling means distribution would also be approximately normal.\nWe can take a look at the CLT in action in a case in which the population distribution is not approximately normal. I will not go much in detail about the distribution itself, as it serves only to demonstrate the CLT.\nWe can see that the data below does not resemble a symmetrical bell-shaped population. It’s heavily skewed towards lower values. In this illustrative case, the population mean is 60.\n\n\n\n\n\n\n\n\n\nBelow, is some code that will take 30 samples (\\(n=30\\)) from this population 10,000 times so that we can create a distribution. I am including it as an example but please do not focus on it too much. The important thing is that it represents us sampling from this clearly not normally distributed population many times.Then, the code plots a histogram of the mean. Can you see how, even though the population mean is not, the sampling mean is approximately normal?\n\nres &lt;- c()\nfor (i in 1:1e4){\nsample &lt;- rgamma(30, shape = 2, scale = 30) \nxbar &lt;- mean(sample)\nres &lt;- c(res, xbar)\n}\nhist(res, \n     main = 'Histogram of the sample mean',\n     xlab = 'Sample mean')"
  },
  {
    "objectID": "posts/2026-02-02_sample-statistics/index.html#particularities-of-the-t-distribution",
    "href": "posts/2026-02-02_sample-statistics/index.html#particularities-of-the-t-distribution",
    "title": "Sample Statistics",
    "section": "Particularities of the \\(t\\) distribution",
    "text": "Particularities of the \\(t\\) distribution\nIn practice, this estimation of the population standard deviation by the sample standard error has an important implication for the \\(t\\) distribution. The distribution changes shape according to the number of samples you have collected. This is where we introduce the concept of degrees of freedom, which can is calculated as \\(n-1\\).\n\nQuick look into degrees of freedom\nThere’s a more formal definition of degrees of freedom that involves linear algebra but, for this class, we can think of degrees of freedom as how much independent information we actually have left once we estimate something from the data.\nWhen we collect a sample and calculate a sample mean, that mean is fixed. Once the mean is fixed, not all observations are free to vary independently anymore. The last observation is constrained by the ones that came before it.\n\n\nRelationship between sample size and the \\(t\\) distribution\nLet’s take a look at the \\(t\\) distribution in comparison to the standard normal distribution for different sample sizes, and then we can think about the effect of sample size.\n\n\n\n\n\n\n\n\n\nAn important characteristic of the \\(t\\) distribution is that, as the sample size increases, the more it approximates to the normal distribution. However, as we can see in the red line above, when sample sizes are low, more extreme values, for example \\(|T| \\geq 2\\) are more common. This means that, when using the \\(t\\) distribution to find differences among treatments, for example, if the sample size is low, you might fail to detect those differences simply because more extreme values are common.\n\n\nCurious fact\nYou might be familiar with the \\(t\\) distribution’s story. It was developed by W. S. Gosset, while working at Guiness, which did not allow employees to publish their work. The work was then published under the name of student, and the distribution is sometimes also called Student t distribution."
  },
  {
    "objectID": "posts/2026-02-02_sample-statistics/index.html#the-t-distribution-in-practice",
    "href": "posts/2026-02-02_sample-statistics/index.html#the-t-distribution-in-practice",
    "title": "Sample Statistics",
    "section": "The \\(t\\) distribution in practice",
    "text": "The \\(t\\) distribution in practice\nOkay, by this point you might be wondering exactly how we will use this concept in practice. I wanted to give you an example to help you visualize how this can be useful.\n\nCase study\nLet’s say you went to a corn field and collected yield samples randomly at 16 locations. The yield averaged 13.8 t/ha with a standard deviation of 2.1 t/ha. Your boss had told you that if you could find statistical evidence that the yield was above 12 t/ha, you would get a bonus for being such a good agronomist.\nLet’s put the \\(t\\) distribution in practice and get that bonus!\n\\[T = \\frac{\\bar{X} - \\mu}{\\frac{S}{\\sqrt{n}}} =\n\\frac{13.8 - 12.0}{\\frac{2.1}{\\sqrt{16}}} = 3.42\\]\nGreat! We got a t-value that we can use to compare to the probability. Let’s use the fastGraph library again and check what is the probability that we get a value t-value outside of 3.42.\nWe can see below that the probability is pretty negligible. Can you even see the red shaded area? Therefore, you could tell your boss to write you a big check!\n\nlibrary(fastGraph)\nshadeDist(xshade = c(-3.42, 3.42),\n          ddist = 'dt',\n          parm1 = 15) ## degrees of freedom: n - 1"
  },
  {
    "objectID": "posts/2026-02-02_sample-statistics/index.html#confidence-intervals",
    "href": "posts/2026-02-02_sample-statistics/index.html#confidence-intervals",
    "title": "Sample Statistics",
    "section": "Confidence intervals",
    "text": "Confidence intervals\nWe can flip the relationships between \\(t\\) and probability to talk about confidence intervals. Let’s say that instead of testing whether a t-value provides evidence that your mean is different from a given value, you want to state an interval for which the population mean is likely to fall within.\nDoing some math, we can say that the confidence interval (CI) can be calculated using the formula below, in which the \\(t\\) value corresponds to the significance level.\n\\[CI = \\bar{x} \\pm t \\times \\frac{S}{\\sqrt{n}}\\]\nLet’s compute the CI for the previous example and let’s use n = 16.\nIn the past, we used t-value tables to guide us in these tests. Have any of you ever seen these? I used them in undergrad.\n\nLuckily, in R, we can retrieve the same information using the qt() function, which stands for quantiles.\nSince we are interested in quantifying the 95% CI, we will use the values 0.025 and 0.975, which leaves 5% of the probability in the outer tails.\n\ntvalues &lt;- qt(c(0.025, 0.975), 15) ## 15 degrees of freedom (n - 1)\ntvalues\n\n[1] -2.13145  2.13145\n\n\nUsing the t-values either from the table or from the qt() function, we can compute the confidence intervals.\n\nupper.boundary &lt;- 13.8 + 2.13 * (2.1/sqrt(16))\nlower.boundary &lt;- 13.8 - 2.13 * (2.1/sqrt(16))\n\nupper.boundary\n\n[1] 14.91825\n\nlower.boundary\n\n[1] 12.68175"
  },
  {
    "objectID": "posts/2026-02-02_sample-statistics/index.html#looking-ahead",
    "href": "posts/2026-02-02_sample-statistics/index.html#looking-ahead",
    "title": "Sample Statistics",
    "section": "Looking ahead",
    "text": "Looking ahead\nThis unit provided in-depth theory of sample statistics and we did a lot of the heavy lifting computations by hand. As I have been showing you, R has functions that can compute these quantities of interest very quickly. However, understanding where those computation come from, the assumptions made when running these computations, and how they can fail is just as important as learning how to use them.\nIn the next unit, we will use these concepts to analyze experimental data in a side-by-side trial. The concepts of the \\(t\\) distribution and confidence intervals are going to help us look for difference among treatments."
  },
  {
    "objectID": "posts/2026-02-06_two-treatment-comparisons/index.html",
    "href": "posts/2026-02-06_two-treatment-comparisons/index.html",
    "title": "Comparisons between two treatments",
    "section": "",
    "text": "So far, we have spent a long time learning about populations and how to use the normal distribution model to represent them. We learned how to compute probabilities, build confidence intervals, and make statements about the population mean (\\(\\mu\\)).\nWe have also looked at how we cannot always collect all the population data, which forces us to rely on samples.\nThen, since we estimate the population variability (\\(\\sigma\\)) using the sample variability (\\(s\\)), we use the \\(t\\)-distribution, which approximates more and more from the normal distribution as we get more samples.\nUsing sample data, we learned how to compute the standard error of the mean, build confidence intervals, and make statements about the population mean using the samples.\n\nAlthough I enjoy this, I understand if you are restless and wondering “how am I going to use any of this in the real world?”\nUp to this point, we focused on estimating one population mean. Now we move to the question agronomists ask most often: comparing treatments."
  },
  {
    "objectID": "posts/2026-02-06_two-treatment-comparisons/index.html#what-are-we-really-asking",
    "href": "posts/2026-02-06_two-treatment-comparisons/index.html#what-are-we-really-asking",
    "title": "Comparisons between two treatments",
    "section": "What are we really asking?",
    "text": "What are we really asking?\nVery often in agronomy (and in other fields as well), we will want to compare two populations to help us make informed decisions. For example, we might want to compare a given fertilizer source, or whether a given corn hybrid outperforms a traditionally grown corn hybrid consistently. Additionally, we might ask whether the yield difference of a given transgenic trait is worth the added cost.\nWhile all of these questions (and many more!) can be asked, we can think of a framework that can generalize these questions. In terms of statistics, what we are really asking is: is the expected value of one population different from the other’s?"
  },
  {
    "objectID": "posts/2026-02-06_two-treatment-comparisons/index.html#what-do-we-expect-from-these-populations",
    "href": "posts/2026-02-06_two-treatment-comparisons/index.html#what-do-we-expect-from-these-populations",
    "title": "Comparisons between two treatments",
    "section": "What do we expect from these populations?",
    "text": "What do we expect from these populations?\nThere is a more formal definition of expected value, but, intuitively, we can think of what you would expect to observe in the population. In a bell-shaped population like the normal distribution, this value would be the population mean (\\(\\mu\\)).\nIn the graph below, you can see an example with corn yield values for two populations. Population 1 has a mean of 180 bu/ac, while population 2 has a mean of 210 bu/ac. You can think of populations 1 and 2 as coming from two different treatments. These can be fertilizer and no fertilizer, fungicide and no fungicide, or hybrid A versus hybrid B.\nSo, when we compare these two populations, we are really asking:\n\\[H_0: \\mu_1 = \\mu_2 \\newline\nor \\newline\nH_a: \\mu_1 \\ne \\mu_2\n\\]\nAnd this is a hypothesis testing problem."
  },
  {
    "objectID": "posts/2026-02-06_two-treatment-comparisons/index.html#hypothesis-testing",
    "href": "posts/2026-02-06_two-treatment-comparisons/index.html#hypothesis-testing",
    "title": "Comparisons between two treatments",
    "section": "Hypothesis testing",
    "text": "Hypothesis testing\nWe already saw a little bit of hypothesis testing in the end of last week’s module, when we tried to get a bonus from our boss showing that we did get a yield greater than 12 t/ha, remember?\nNow, let’s look at the structure for this type of test:\n\nWe formulate the hypothesis we want to test — in this case, whether the two population means differ (\\(H_a\\)).\nThen, we formulate what is the null hypothesis (\\(H_0\\)), which is mutually exclusive with the hypothesis we are testing.\nWe collect the data and test whether we can reject the null hypothesis. When we can, this provides evidence for the alternative hypothesis, but we can never prove that the alternative hypothesis is true.\n\nThere are hundreds of tests that can be used to test hypotheses. Here, we will focus on the paired \\(t\\)-test because it is designed to test the difference between two groups, which is a common agronomic problem."
  },
  {
    "objectID": "posts/2026-02-06_two-treatment-comparisons/index.html#the-paired-t-test",
    "href": "posts/2026-02-06_two-treatment-comparisons/index.html#the-paired-t-test",
    "title": "Comparisons between two treatments",
    "section": "The paired \\(t\\)-test",
    "text": "The paired \\(t\\)-test\nOne way of looking for the difference in two populations is to look at the distribution of that difference. Translating this to the hypothesis testing framework, this becomes:\n\\[H_0: \\mu_1 = \\mu_2 \\rightarrow \\mu_1 - \\mu_2  =0 \\newline\nH_a: \\mu_1 \\ne \\mu_2\\rightarrow \\mu_1 - \\mu_2   \\ne 0\\]\n\nCase study\nThe paired \\(t\\)-test allows us to compute some of the same statistics as we did in last class (t-value and confidence interval) for the difference between the plots within a pair. Let’s take a look at a trial in central Ohio in which they tested a starter fertilizer versus without the starter. Hopefully, then, the concept of a paired design will be clearer.\n\nLooking at the data\nIn the figure below, you can see that going left-to-right, we have different pairs of experimental units (which are distributed up and down). In this case, the experimental units are randomized only within each pair (which the textbook calls a block).\nThis imposed structure is what allows us to conduct the paired \\(t\\)-test. If these experimental units had been distributed randomly throughout the field, this would not be an appropriate test.\n\n\n\n\n\n\n\n\n\nLet’s take a look at the data. As we can see, each block has a pair of plots inside.\n\n\n  block plot treatment yield\n1     1   11   Starter 193.4\n2     1   12   Control 194.2\n3     2   21   Starter 192.2\n4     2   22   Control 189.0\n5     3   31   Control 193.8\n6     3   32   Starter 194.2\n\n\nLet’s take a look at the yield value of these treatments. In the plot below, the open circles represent the different observations for each treatment, and the triangle and error bar represent the sample mean plus or minus the standard error.\nIt seems like, on average, the yield when using the started was indeed greater. However, how can we test this hypothesis?\nHere is the code for reference. I think it is important to be exposed to this ggplot syntax :)\n\nggplot(corn)+\n  geom_point(aes(x = yield, y = treatment), pch = 1)+\n  labs(x = 'Yield (bu/ac)', y = 'Treatment')+\n  stat_summary(aes(x = yield, y = treatment),\n               pch = 17,\n               fun.data = 'mean_se')+\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nComputing differences\nWe want to test whether the mean difference between these treatments is zero. Let’s begin by computing the differences within each pair.\n\n\n193.4-194.2 = -0.8 \n192.2-189 = 3.2 \n194.2-193.8 = 0.4 \n190.5-186.4 = 4.1 \n198.7-196.4 = 2.3 \n193.4-189.8 = 3.6 \n196-187.6 = 8.4 \n196.7-185.3 = 11.4 \n201.5-184.5 = 17 \n198.9-192.6 = 6.3 \n\n\nLet’s put these numbers on a graph so we can have a better look. It seems like very often, the starter fertilizer provided a yield boost. Once again, the open circles represent the different observations for each treatment, and the triangle and error bar represent the sample mean plus or minus the standard error.\nOn average, we see a yield increase of 5.6 bu/ac. This shows promise but let’s see if, given the variability in this dataset, we would expect to see an increase consistently if we ran this experiment multiple times. You know where this is going, right?\n\n\n\n\n\n\n\n\n\n\n\nConfidence interval\nTo build our confidence intervals here, we will need a couple of things:\n\nA vector containing the differences\nCompute sample mean and standard error\nChoose a significance level (e.g., 95% or 99%)\nBring all of these pieces together\n\nHere, we can see a vector in which I collected all the differences within each pair/block.\n\ndifferences\n\n   1    2    3    4    5    6    7    8    9   10 \n-0.8  3.2  0.4  4.1  2.3  3.6  8.4 11.4 17.0  6.3 \n\n\nNext, let’s compute the mean and standard error\n\nxbar &lt;- mean(differences)\nn &lt;- length(differences)\ns &lt;- sd(differences) / sqrt(n)\n\nxbar\n\n[1] 5.59\n\nn\n\n[1] 10\n\ns\n\n[1] 1.708895\n\n\nNow, let’s check a value of \\(t\\) that would correspond to 95% of the probability distribution area\n\ntval &lt;- qt(p = c(0.025, 0.975),\n   df = n - 1)\ntval\n\n[1] -2.262157  2.262157\n\n\nNow, the final step, we bring all of these pieces together and build a confidence interval\n\nci &lt;- xbar + (tval * s)\nci\n\n[1] 1.724211 9.455789\n\n\n\n\nInterpreting these numbers\nI would like to take a second to interpret these numbers. If we think about it, what do they represent?\nThese numbers indicate that the difference between these two sample means, if the experiment were repeated many many many times, would be between 1.72 and 9.46 bu/ac.\nThe fact that the lower bound does not include 0 is already an indication of the result of the \\(t\\)-test, but let’s conduct the test to verify.\n\n\n\\(t\\)-test\nTo conduct the \\(t\\)-test, we flip the structure we used for the confidence interval. Instead of choosing a t-value that would correspond to a certain significance level, we compute the t statistic, as in last module.\n\\[T = \\frac{\\bar{X} - \\mu}{\\frac{S}{\\sqrt{n}}}\\]\nIn this case, let’s compute it for this dataset.\n\\[T = \\frac{\\bar{X} - \\mu}{\\frac{S}{\\sqrt{n}}} = \\frac{5.59 - 0}{1.71} = 3.27\\]\nThen, we can check using the fastGraph library. This shows us that the probability of us observing a t-statistic value more extreme than the one we observed (3.27) would be very small (&lt; 0.01).\nThinking about the hypothesis testing scenario, we could say that there is strong evidence to reject the null hypothesis ($H_0 : _1 - _2 = 0 $).\n\n\n\n\n\n\n\n\n\n\n\n\nR built-in methods\nSince R is a programming language with a strong inclination towards statistics, it already has pre-built methods for this.\nThe t.test() function is what we would use in this case. The use of this function would go something like this.\n\nt.test(x = VECTOR WITH GROUP 1 DATA,\n       y = VECTOR WITH GROUP 2 DATA,\n       paired = TRUE)\n\n\nReshaping the data\nSince we have to split this data frame between two vectors, this requires wrangling the data a little bit. We have to take the data from a long format, to a wide format. In this case, this is important to make sure that we do not mix up the yield data between blocks. I will not show how to do this here, as it would be distracting. We have an exercise dedicated to this.\nWe have to go from this:\n\n\n   block plot treatment yield\n2      1   12   Control 194.2\n1      1   11   Starter 193.4\n4      2   22   Control 189.0\n3      2   21   Starter 192.2\n5      3   31   Control 193.8\n6      3   32   Starter 194.2\n8      4   42   Control 186.4\n7      4   41   Starter 190.5\n9      5   51   Control 196.4\n10     5   52   Starter 198.7\n11     6   61   Control 189.8\n12     6   62   Starter 193.4\n14     7   72   Control 187.6\n13     7   71   Starter 196.0\n15     8   81   Control 185.3\n16     8   82   Starter 196.7\n18     9   92   Control 184.5\n17     9   91   Starter 201.5\n19    10  101   Control 192.6\n20    10  102   Starter 198.9\n\n\nTo this:\n\n\n   block yield.Control yield.Starter\n2      1         194.2         193.4\n4      2         189.0         192.2\n5      3         193.8         194.2\n8      4         186.4         190.5\n9      5         196.4         198.7\n11     6         189.8         193.4\n14     7         187.6         196.0\n15     8         185.3         196.7\n18     9         184.5         201.5\n19    10         192.6         198.9\n\n\n\n\nRunning a t-test\nNow that our dataset has been reshaped, we can confidently run a paired \\(t\\)-test. Note that you have to specify within the function that the design was paired.\nJust like that, within one function, we get the same values we’ve just manually calculated.\n\nt.test(corn_wide$yield.Starter,\n       corn_wide$yield.Control,\n       paired = TRUE)\n\n\n    Paired t-test\n\ndata:  corn_wide$yield.Starter and corn_wide$yield.Control\nt = 3.2711, df = 9, p-value = 0.009665\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 1.724211 9.455789\nsample estimates:\nmean difference \n           5.59"
  },
  {
    "objectID": "posts/2026-02-06_two-treatment-comparisons/index.html#what-about-a-not-paired-case",
    "href": "posts/2026-02-06_two-treatment-comparisons/index.html#what-about-a-not-paired-case",
    "title": "Comparisons between two treatments",
    "section": "What about a not paired case?",
    "text": "What about a not paired case?\nWhen we do not have a paired case, we cannot simply compute the differences within a pair and compute the t-test of that difference. There’s a slightly more involved calculation.\nWhat I aim to do here is to help you identify when you should use the paired and the common “two-sample \\(t\\)-test”.\nIn this case, a non-paired \\(t\\)-test would be appropriate if the experimental units were free to vary within the design. In other words, if we had not restricted the design to guarantee that each block/pair (going in the x-axis in the image below), had both treatments, we would use a non-paired \\(t\\)-test.\n\n\n\n\n\n\n\n\n\n\nRunning a non-paired \\(t-test\\)\nAlthough we could go over the calculations for the non-paired \\(t\\)-test, I believe we do not gain much from investing the time in it. The paired case is much more common in agronomic setting with two treatments. Partly because pairing experimental units saves a lot of headaches with within-field variability.\nNon-paired designs, in general, will be those with more than two treatments, and we will discuss those in the coming weeks!\nTo run the t-test in R, we can simply change the paired argument to FALSE. Now, observed that the output is quite different.\n\nt.test(corn_wide$yield.Starter,\n       corn_wide$yield.Control,\n       paired = FALSE)\n\n\n    Welch Two Sample t-test\n\ndata:  corn_wide$yield.Starter and corn_wide$yield.Control\nt = 3.3032, df = 17.444, p-value = 0.004087\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 2.026469 9.153531\nsample estimates:\nmean of x mean of y \n   195.55    189.96"
  },
  {
    "objectID": "posts/2025-07-19_as-applied/index.html",
    "href": "posts/2025-07-19_as-applied/index.html",
    "title": "Processing as-applied and as-planted data in on-farm trials",
    "section": "",
    "text": "In the context of on-farm research, we often apply treatments using variable rate applicators to investigate how these different treatments will affect crop yield. An important piece of extracting treatment effects is to process the “as-applied” or “as-planted” data, in the cases of fertilizer and planting data, respectively.\nWe have just released a new function called pa_trial, to process these data. The function can help us process as-applied data and aggregate these data at the level of experimental unit, so we can model the yield response to treatment.\nThe pa_trial function is still experimental, and we are still testing it and making sure that the function arguments are intuitive for general use. These might change in the development version but, when we release a final version to CRAN, these will be set. If you use the package and find any issues with the pa_trial function, please report it to us so we can fix it."
  },
  {
    "objectID": "posts/2025-07-19_as-applied/index.html#introduction",
    "href": "posts/2025-07-19_as-applied/index.html#introduction",
    "title": "Processing as-applied and as-planted data in on-farm trials",
    "section": "",
    "text": "In the context of on-farm research, we often apply treatments using variable rate applicators to investigate how these different treatments will affect crop yield. An important piece of extracting treatment effects is to process the “as-applied” or “as-planted” data, in the cases of fertilizer and planting data, respectively.\nWe have just released a new function called pa_trial, to process these data. The function can help us process as-applied data and aggregate these data at the level of experimental unit, so we can model the yield response to treatment.\nThe pa_trial function is still experimental, and we are still testing it and making sure that the function arguments are intuitive for general use. These might change in the development version but, when we release a final version to CRAN, these will be set. If you use the package and find any issues with the pa_trial function, please report it to us so we can fix it."
  },
  {
    "objectID": "posts/2025-07-19_as-applied/index.html#installing-the-necessary-packages",
    "href": "posts/2025-07-19_as-applied/index.html#installing-the-necessary-packages",
    "title": "Processing as-applied and as-planted data in on-farm trials",
    "section": "Installing the necessary packages",
    "text": "Installing the necessary packages\nThe pa_trial function can be found in the development version of pacu on GitHub. We will use two libraries for this example, pacu and sf. In case you do not have them installed, you can install them using the following code chunk\n\ninstall.packages('sf')\n\n## we will install pacu from GitHub because of some newly added features\n## version 0.1.70\nremotes::install_github('cldossantos/pacu')\n\nLet’s load the libraries:\n\nlibrary(sf)\nlibrary(pacu)"
  },
  {
    "objectID": "posts/2025-07-19_as-applied/index.html#reading-the-data-in",
    "href": "posts/2025-07-19_as-applied/index.html#reading-the-data-in",
    "title": "Processing as-applied and as-planted data in on-farm trials",
    "section": "Reading the data in",
    "text": "Reading the data in\nFor this example, we will use three simulated data sets that were built for this example. These data simulate a maize on-farm experiment that had both nitrogen and seeding rate treatments. In this particular case, I simulated an existing relationship between yield and nitrogen, but no relationship between yield and seeding rate. Let’s see if we can recover these relationships!\nHere, all the raw data that we will use in this example:\n\nTrial design: This data set contains the geometries and prescriptions for nitrogen and seeding rates\nAs-planted: This data set comes from the planter’s monitor and shows what was the planted population at each data point\nAs-applied nitrogen: This data set comes from the variable rate applicator and contains the applied nitrogen rate at each data point\nRaw yield: Data from the yield monitor showing the yield registered at each data point\n\n\ntrial.design &lt;- st_read('./raw-data/trial-design.shp')\nplanted.seed &lt;- st_read('./raw-data/as-planted.shp')\napplied.n &lt;- st_read('./raw-data/as-applied-nitrogen.shp')\nraw.yield &lt;- st_read('./raw-data/synthetic-raw-yield.shp')"
  },
  {
    "objectID": "posts/2025-07-19_as-applied/index.html#taking-a-first-look-at-the-data",
    "href": "posts/2025-07-19_as-applied/index.html#taking-a-first-look-at-the-data",
    "title": "Processing as-applied and as-planted data in on-farm trials",
    "section": "Taking a first look at the data",
    "text": "Taking a first look at the data\n\nAs-planted\nLet’s take a look at the planter’s data, which shows the seeding rate at each point. To facilitate visualization, let’s include the trial design grid as well.\n\nplot(planted.seed['plant_pop_'], \n     main = 'Seeding density (k seeds/ac)',\n     cex = 0.5,\n     pch = 16,\n     reset = FALSE)\nplot(st_geometry(trial.design), add = TRUE)\n\n\n\n\n\n\n\n\n\n\nAs-applied nitrogen\nLet’s take a look at the variable rate applicator’s data. This data shows how much urea was applied at each data point.\n\nplot(applied.n['appliedrt'], \n     main = 'Applied Urea (lb/ac)',\n     cex = 0.5,\n     pch = 16,\n     reset = FALSE)\nplot(st_geometry(trial.design), add = TRUE)\n\n\n\n\n\n\n\n\n\n\nRaw yield\nLet’s take a look at the yield monitor’s data. This will tell us what was the yield at each data point.\n\nplot(raw.yield['Yield'], \n     main = 'Maize yield (bu/ac)',\n     cex = 0.3,\n     pch = 16,\n     reset = FALSE)\n\nplot(st_geometry(trial.design), add = TRUE)"
  },
  {
    "objectID": "posts/2025-07-19_as-applied/index.html#bringing-these-datasets-together",
    "href": "posts/2025-07-19_as-applied/index.html#bringing-these-datasets-together",
    "title": "Processing as-applied and as-planted data in on-farm trials",
    "section": "Bringing these datasets together",
    "text": "Bringing these datasets together\nNow that we have seen each data set separately, we need to bring these data sets together so we can investigate the relationship between our imposed treatments and yield. To do that, we will process both the variable rate and the planter data using pa_trial, and then we will process the yield monitor data using pa_yield. For all the next steps, we will use the ritas algorithm. You can find more information about how we implemented this algorithm in the original publication of pacu.\nBefore we process these data, I will remove the big bordering area around our experimental plots just to reduce the amount of data we will process. This can be done before or after processing the data but doing it before, saves you some processing time.\n\ntrial.design &lt;- subset(trial.design, type == 'Trial')\nplot(st_geometry(trial.design))\n\n\n\n\n\n\n\n\n\nAs-planted\nHere, we will use pa_trial to process the as-planted data. The function requires the user to specify which column in the input data set corresponds to the “trial” column. In this case, the seeding density is in a column called plant_pop_. I am also specifying that the units of the planter’s width are “ft”. I use a conversion factor of 2.47 to convert from acre to hectare as well.\n\nprocessed.seed &lt;- pa_trial(planted.seed,\n                           data.columns = c(trial = 'plant_pop_'),\n                           data.units = c(trial = 'k seeds/ac',\n                                          width = 'ft'),\n                           grid = trial.design,\n                           algorithm = 'ritas',\n                           var.label = 'seeds',\n                           conversion.factor = 2.47,\n                           out.units = 'k seeds/ha',\n                           verbose = FALSE, ## suppressing progress bar\n                           cores = 6) ## for speed\n\nGuessing units of angle to be degreeN\n\n\nGuessing units of distance to be ft\n\n\nUsing pa_trial, we aggregated the seed data at the level of experimental unit, as can be seen below.\n\npa_plot(processed.seed)\n\n\n\n\n\n\n\n\n\n\nAs-applied nitrogen\nHere, we will follow the same process that we used to process the seeding density data set. The one difference is that the conversion factors change. Since the nitrogen data is as urea, we will use a conversion factor of 0.45 to reflect the nitrogen content in the urea, and then 1.12 to convert from \\(lb.ac^{-1}\\) to \\(kg.ha^{-1}\\).\n\nprocessed.nitrogen &lt;- pa_trial(applied.n,\n                               data.columns = c(trial = 'appliedrt'),\n                               data.units = c(trial = 'lb Urea/ac',\n                                              width = 'ft'),\n                               grid = trial.design,\n                               algorithm = 'ritas',\n                               var.label = 'nitrogen',\n                               conversion.factor = 0.45 * 1.12,\n                               out.units = 'kg N/ha',\n                               verbose = 0,\n                               cores = 6)\n\nGuessing units of angle to be degreeN\n\n\nGuessing units of distance to be ft\n\n\nUsing pa_trial, we aggregated the nitrogen data at the level of experimental unit, as can be seen below.\n\npa_plot(processed.nitrogen)\n\n\n\n\n\n\n\n\n\n\nMerging the treatment datasets\nNow that both treatment data sets are processed, we can combine them into a single object.\n\ntreatments &lt;- merge(processed.nitrogen, processed.seed)\nprint(treatments)\n\nVariables in trial object:\n------------------------------------------\nVariable  Algorithm  Smoothing  Units      \n---       ---        ---        ---        \nnitrogen  ritas      none       kg N/ha    \nseeds     ritas      none       k seeds/ha \n------------------------------------------\n\nVariable summary:\n------------------------\n         nitrogen  seeds \n---      ---       ---   \nMin.     59.315087 71.610\n1st Qt.  83.723312 80.764\nMedian   109.88047 86.883\n3rd Qt.  132.25985 93.063\nMax.     160.26292 101.50\nMean     108.21485 87.039\nNAs      0         0     \n------------------------\n\npa_plot(treatments)\n\n\n\n\n\n\n\n\n\n\nYield monitor data\nAfter processing all the treatment data, we can pass the treatments object to the “grid” argument and the resulting object will contain all the information regarding treatments and yield. The pa_yield function will try to guess the units of the variables it uses to process the yield monitor data. Pay attention to these and, in case they are not correct, you can override the guess by passing the argument “data.units”.\n\nprocessed.yield &lt;- pa_yield(raw.yield,\n                            grid = treatments,\n                            algorithm = 'ritas',\n                            formula = z ~ fid,\n                            smooth.method = 'krige',\n                            unit.system = 'metric',\n                            remove.crossed.polygons = TRUE,\n                            steps = TRUE,\n                            verbose = FALSE,\n                            cores = 6)\n\nGuessing units of interval to be s\n\n\nGuessing units of moisture to be %\n\n\nGuessing units of flow to be lb/s\n\n\nGuessing units of angle to be degreeN\n\n\nGuessing units of width to be ft\n\n\nGuessing units of distance to be ft\n\n\nWe can see the processed yield data below\n\npa_plot(processed.yield)"
  },
  {
    "objectID": "posts/2025-07-19_as-applied/index.html#looking-at-the-relationships-between-yield-and-the-treatment-variables",
    "href": "posts/2025-07-19_as-applied/index.html#looking-at-the-relationships-between-yield-and-the-treatment-variables",
    "title": "Processing as-applied and as-planted data in on-farm trials",
    "section": "Looking at the relationships between yield and the treatment variables",
    "text": "Looking at the relationships between yield and the treatment variables\nBelow, we can examine the relationship between yield and both treatment variables: nitrogen and seeding rate. The next steps are really independent from pacu. One can choose to model these data using whatever modeling framework they are most comfortable with, or judge the most adequate. Since the idea of this post is to demonstrate how pacu can aid in analyzing on-farm experimental data, I will stop here.\n\nwith(processed.yield$yield, \n     plot(nitrogen, \n          yield, \n          col = 4,\n          xlab = 'Nitrogen rate (kg N/ha)',\n          ylab = 'Yield (t/ha)'))\n\n\n\n\n\n\n\nwith(processed.yield$yield, \n     plot(seeds, \n          yield, \n          col = 4,\n          xlab = 'Seeding rate (k seeds/ha)',\n          ylab = 'Yield (t/ha)'))"
  },
  {
    "objectID": "posts/2025-07-19_as-applied/index.html#conclusion",
    "href": "posts/2025-07-19_as-applied/index.html#conclusion",
    "title": "Processing as-applied and as-planted data in on-farm trials",
    "section": "Conclusion",
    "text": "Conclusion\nIn this post we saw how the new pa_trial function can be used to process as-applied data from variable rate technologies in on-farm trials. We showed how to aggregate planting and nitrogen application data to the level of the experimental unit and combine them with yield monitor data for further analysis.\nBy doing so, we can move beyond simply knowing what was intended in an experimental design to understanding what was actually applied in the field—an important distinction when modeling treatment effects in precision agriculture.\nIf you have to process some of these data, you should definitely give pacu a try and let me know how it goes! We’ll be back with more updates on pacu soon! Stay tuned!"
  },
  {
    "objectID": "posts/2025-12-03_experimental-design/index.html",
    "href": "posts/2025-12-03_experimental-design/index.html",
    "title": "Experimental Design - How many controls to include in a factorial experiment?",
    "section": "",
    "text": "Recently, I was talking to some friends about experimental design (exciting topic, right?!) and we reached a topic that I had not thought would be a controversy before. When we are planning an experiment, how many controls should we include? I guess the answer to that question is often the usual agronomist answer: it depends.\nIn many agronomic experiments, this question really hinges on how we conceptualize the “control.” If “control” is simply the 0 rate of a fertilizer, then it is a level of the rate factor, not a separate source. But if we treat “control” as its own fertilizer source, we have implicitly changed the structure of the experiment.\nIn this post, I will explore some of my ideas on the topic. I do not claim that they are universally valid, but I will explain my train of thought so you can judge whether these ideas apply to your case. Let’s dive into it!"
  },
  {
    "objectID": "posts/2025-12-03_experimental-design/index.html#introduction",
    "href": "posts/2025-12-03_experimental-design/index.html#introduction",
    "title": "Experimental Design - How many controls to include in a factorial experiment?",
    "section": "",
    "text": "Recently, I was talking to some friends about experimental design (exciting topic, right?!) and we reached a topic that I had not thought would be a controversy before. When we are planning an experiment, how many controls should we include? I guess the answer to that question is often the usual agronomist answer: it depends.\nIn many agronomic experiments, this question really hinges on how we conceptualize the “control.” If “control” is simply the 0 rate of a fertilizer, then it is a level of the rate factor, not a separate source. But if we treat “control” as its own fertilizer source, we have implicitly changed the structure of the experiment.\nIn this post, I will explore some of my ideas on the topic. I do not claim that they are universally valid, but I will explain my train of thought so you can judge whether these ideas apply to your case. Let’s dive into it!"
  },
  {
    "objectID": "posts/2025-12-03_experimental-design/index.html#how-did-this-discussion-start",
    "href": "posts/2025-12-03_experimental-design/index.html#how-did-this-discussion-start",
    "title": "Experimental Design - How many controls to include in a factorial experiment?",
    "section": "How did this discussion start?",
    "text": "How did this discussion start?\nWe started talking about this when thinking about how to analyze an experiment that had already been conducted in a controlled environment. The experiment was relatively simple, and the researchers wanted to evaluate the effect of fertilizer source (e.g., synthetic fertilizer, manure, digestate) and rate (i.e., how much fertilizer was applied) on nitrogen oxide emissions. In addition, they had four replications of the treatments.\nSo, this experiment had two factors: rate and source. If this experiment were planned to follow a factorial design, we would have had all combinations of all levels of both factors. The nitrogen rates ranged from 0 to 300 kg/ha, in 60 kg/ha intervals, and there were 3 sources of nitrogen. The experimental design should look something like this:\n\nrates &lt;- seq(0, 300, 60)\nsources &lt;- c('synthetic', 'manure', 'digestate')\nreplications &lt;- 1:4\nexperimental.structure &lt;- expand.grid(rate = rates,\n                                      source = sources,\n                                      rep = replications,\n                                      stringsAsFactors = FALSE)\n\nThe number of experimental units per combination of factors would be four, resulting in 72 experimental units.\n\nwith(experimental.structure,addmargins(table(source, rate)))\n\n           rate\nsource       0 60 120 180 240 300 Sum\n  digestate  4  4   4   4   4   4  24\n  manure     4  4   4   4   4   4  24\n  synthetic  4  4   4   4   4   4  24\n  Sum       12 12  12  12  12  12  72\n\n\nHowever, that’s not how the experiment was planned. Since the rate “0” means that no nitrogen source was applied, the researchers decided to include a single set of 0-nitrogen experimental units to serve as their control. By doing this, they eliminated 8 experimental units from the design, potentially saving time and resources but, in my view, creating some problems for the analysis. This is not the first time I have seen this, as this strategy is common in agronomic experiments. As someone who has collected a lot of data in the field, I understand the urge to save resources. However, let’s take a look at what this means for the analysis.\n\nexperimental.structure2 &lt;- experimental.structure\nexperimental.structure2 &lt;- subset(experimental.structure2,\n                                  !(rate == 0 & source %in% c('manure', 'digestate')))\nexperimental.structure2$source[experimental.structure2$rate == 0] &lt;- 'control'\nwith(experimental.structure2,addmargins(table(source, rate)))\n\n           rate\nsource       0 60 120 180 240 300 Sum\n  control    4  0   0   0   0   0   4\n  digestate  0  4   4   4   4   4  20\n  manure     0  4   4   4   4   4  20\n  synthetic  0  4   4   4   4   4  20\n  Sum        4 12  12  12  12  12  64\n\n\nThe table above brings to light a problem that this experimental design has in the analysis stage. Should the “control” experimental units be in their own “source” level? Or should they be assigned to one of the pre-existing levels of source? I think we can understand the implications of this experimental design a little bit better with a more concrete example."
  },
  {
    "objectID": "posts/2025-12-03_experimental-design/index.html#lets-build-an-example",
    "href": "posts/2025-12-03_experimental-design/index.html#lets-build-an-example",
    "title": "Experimental Design - How many controls to include in a factorial experiment?",
    "section": "Let’s build an example",
    "text": "Let’s build an example\nLet us build a conceptual example in which both manure and digestate present similar responses to nitrogen rate in terms of nitrogen emissions, and synthetic fertilizer presents a greater potential for emissions.\nThis conceptual response to nitrogen rate can be seen in this function, in which the rate of emission increases when the source is “synthetic.” For this exercise, we will pretend that this is the true relationship that we are trying to uncover by running this experiment.\n\nconceptual.response &lt;- function(x, a, b, src){\n  if(src == 'synthetic')\n    b &lt;- b + 0.05\n  resp &lt;- a + b * x\n  resp\n}\n\nconceptual.response &lt;- Vectorize(conceptual.response,\n                                 c('x', 'src'))\nxvec &lt;- 0:300\nplot(xvec,\n     conceptual.response(xvec, 6, 0.1, 'not synthetic'),\n     xlab = 'N rate', \n     ylab = 'Emissions', \n     type = 'l')\nlines(xvec,\n     conceptual.response(xvec, 6, 0.1, 'synthetic'),\n     col = 'red')\nlegend('topleft',\n       lty = 1,\n       col = c('black', 'red'),\n       legend = c('Not synthetic', 'synthetic'))\n\n\n\n\n\n\n\n\nHere I am using a simple linear relationship to keep the example transparent. This is not meant to imply emissions must be linear in real systems, just that linear models clearly reveal what happens when treatment combinations are missing. The slopes in the simulated example (0.01 for non-synthetic and +0.05 additional slope for synthetic) are chosen for numerical clarity rather than biological realism."
  },
  {
    "objectID": "posts/2025-12-03_experimental-design/index.html#factorial-design",
    "href": "posts/2025-12-03_experimental-design/index.html#factorial-design",
    "title": "Experimental Design - How many controls to include in a factorial experiment?",
    "section": "Factorial design",
    "text": "Factorial design\nLet’s see how well we can uncover this relationship when we use a full factorial design.\n\nnoise &lt;- rnorm(nrow(experimental.structure),\n               mean = 0,\n               sd = 2)\nexperimental.structure$emissions &lt;- with(experimental.structure,\n                                         conceptual.response(rate,\n                                                             6, \n                                                             0.01,\n                                                             source)) + noise\n\n\nplot(experimental.structure$rate,\n     experimental.structure$emissions,\n     pch = 16,\n     col = hcl.colors(3, 'Set 2')[as.factor(experimental.structure$source)],\n     xlab = 'N rate',\n     ylab = 'Emissions')\n\nlegend('topleft',\n       pch = 16,\n       col =  hcl.colors(3, 'Set2'),\n       legend = levels(as.factor(experimental.structure$source)))\n\n\n\n\n\n\n\n\nHere, we have all levels represented and the mock data can be used to model the relationship between our response variable and the factors rate and source. This model was able to estimate all the effects that we were interested in. Now, let’s see what happens when we include only one control.\n\nfit1 &lt;- lm(emissions ~ rate + source + rate:source,\n           data = experimental.structure)\nsummary(fit1)\n\n\nCall:\nlm(formula = emissions ~ rate + source + rate:source, data = experimental.structure)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.2294 -1.0870 -0.0345  1.3839  3.1044 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           6.9864257  0.6949355  10.053 6.09e-15 ***\nrate                  0.0080260  0.0038255   2.098   0.0397 *  \nsourcemanure          0.1292932  0.9827872   0.132   0.8957    \nsourcesynthetic      -1.3267799  0.9827872  -1.350   0.1816    \nrate:sourcemanure    -0.0007077  0.0054101  -0.131   0.8963    \nrate:sourcesynthetic  0.0507216  0.0054101   9.375 9.41e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.92 on 66 degrees of freedom\nMultiple R-squared:  0.8626,    Adjusted R-squared:  0.8522 \nF-statistic: 82.89 on 5 and 66 DF,  p-value: &lt; 2.2e-16\n\n\nThis model correctly estimates all main effects and interactions because the design contains every treatment combination. Importantly, the model is assuming linearity with respect to rate, but that choice is independent from the factorial structure. Even nonlinear models would require all treatment combinations to be present to identify source-specific responses."
  },
  {
    "objectID": "posts/2025-12-03_experimental-design/index.html#including-only-one-control",
    "href": "posts/2025-12-03_experimental-design/index.html#including-only-one-control",
    "title": "Experimental Design - How many controls to include in a factorial experiment?",
    "section": "Including only one control",
    "text": "Including only one control\n\nnoise &lt;- rnorm(nrow(experimental.structure2),\n               mean = 0,\n               sd = 2)\nexperimental.structure2$emissions &lt;- with(experimental.structure2,\n                                         conceptual.response(rate,\n                                                             6, \n                                                             0.01,\n                                                             source)) + noise\n\nHere, we can see a first source of uncertainty/awkwardness. We need to decide what to do with the “control” plots. Do we leave them by themselves in the “control” category? Should we assign the control to one of the other fertilizer sources? Let’s proceed by leaving the “control” experimental units in their own category.\n\nControl experimental units in their own category\nLet’s visualize these data to understand this source of uncertainty better. We have four observations sitting at the 0-nitrogen rate and assigned to the control treatment. Somehow, these observations are supposed to help us estimate the relationship between nitrogen emissions and nitrogen rate for the other three “source” treatments.\nNext, we can proceed to fitting the same model as before and see if we can estimate all model parameters.\n\nplot(experimental.structure2$rate,\n     experimental.structure2$emissions,\n     pch = 16,\n     col = hcl.colors(4, 'Set 2')[as.factor(experimental.structure2$source)],\n     xlab = 'N rate',\n     ylab = 'Emissions')\n\nlegend('topleft',\n       pch = 16,\n       col =  hcl.colors(4, 'Set2'),\n       legend = levels(as.factor(experimental.structure2$source)))\n\n\n\n\n\n\n\n\n\nfit2.1 &lt;- lm(emissions ~ rate + source + rate:source,\n           data = experimental.structure2)\n\nsummary(fit2.1)\n\n\nCall:\nlm(formula = emissions ~ rate + source + rate:source, data = experimental.structure2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.7437 -0.9386  0.0044  0.9080  3.5050 \n\nCoefficients: (1 not defined because of singularities)\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           6.341195   0.811710   7.812 1.41e-10 ***\nrate                  0.052725   0.004278  12.324  &lt; 2e-16 ***\nsourcedigestate      -1.715206   1.176279  -1.458    0.150    \nsourcemanure         -0.138808   1.176279  -0.118    0.906    \nsourcesynthetic       1.199119   1.176279   1.019    0.312    \nrate:sourcedigestate -0.040361   0.006050  -6.671 1.12e-08 ***\nrate:sourcemanure    -0.045019   0.006050  -7.441 5.86e-10 ***\nrate:sourcesynthetic        NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.623 on 57 degrees of freedom\nMultiple R-squared:  0.9223,    Adjusted R-squared:  0.9142 \nF-statistic: 112.8 on 6 and 57 DF,  p-value: &lt; 2.2e-16\n\n\nOne of the first things we can see is that estimating the interaction terms can be problematic. We are missing some levels, which can be seen as zero counts in this table. This prevents us from estimating the interaction terms.\n\nwith(experimental.structure2, addmargins(table(source, rate)))\n\n           rate\nsource       0 60 120 180 240 300 Sum\n  control    4  0   0   0   0   0   4\n  digestate  0  4   4   4   4   4  20\n  manure     0  4   4   4   4   4  20\n  synthetic  0  4   4   4   4   4  20\n  Sum        4 12  12  12  12  12  64\n\n\n\n\nReplicating the control data\nOne of the ways I have seen researchers deal with this problem in the analysis is by replicating the control data to the other experimental units. I think the idea is that the control should present about the same variability regardless of treatment combination. However, I believe this is a major violation of the model assumptions. Namely, this violates the assumption of independence of the residuals. Are there residuals more dependent among themselves than those from copied data? :)\nI will show here what I mean by this, but I am not recommending this to anyone.\n\nexperimental.structure3 &lt;- experimental.structure2\ncontrol.indices &lt;- which(experimental.structure3$source == 'control')\nexperimental.structure3 &lt;- rbind(experimental.structure3,\n                                 experimental.structure3[rep(control.indices, 2), ])\n\ncontrol.indices &lt;- which(experimental.structure3$source == 'control')\nexperimental.structure3$source[control.indices] &lt;- rep(unique(experimental.structure$source), rep(4, 3))\n\nThis data set now contains a structure similar to the first data set, but models fit using these data violate an important assumption of regression models. Additionally, this approach artificially inflates the number of observations in the data set. In turn, this reduces standard errors and increases the chances of finding differences when there are none.\n\nwith(experimental.structure3, addmargins(table(source, rate)))\n\n           rate\nsource       0 60 120 180 240 300 Sum\n  digestate  4  4   4   4   4   4  24\n  manure     4  4   4   4   4   4  24\n  synthetic  4  4   4   4   4   4  24\n  Sum       12 12  12  12  12  12  72"
  },
  {
    "objectID": "posts/2025-12-03_experimental-design/index.html#my-two-cents",
    "href": "posts/2025-12-03_experimental-design/index.html#my-two-cents",
    "title": "Experimental Design - How many controls to include in a factorial experiment?",
    "section": "My two cents :)",
    "text": "My two cents :)\nI decided to write this text out of a conversation I had with a friend to show how I think about this. I believe there might be people out there with alternative points of view, and I would love to hear more about it. For what it is worth, I believe that experimental design is an important and often overlooked step in the scientific process. I can only imagine how frustrating it would be to run a trial and then not be able to run the analysis correctly.\nI think the main message here is that statistical identifiability is not something we can recover after the fact. Once certain treatment combinations are missing from the experimental design, we might not be able to answer the scientific questions that we set out to investigate."
  },
  {
    "objectID": "posts/2026-02-19_understanding-statistical-tests/index.html",
    "href": "posts/2026-02-19_understanding-statistical-tests/index.html",
    "title": "Understanding Statistical Tests",
    "section": "",
    "text": "So far in this course, we have:\n\nDescribed populations using the normal distribution\n\nLearned about sampling variability\n\nIntroduced the \\(t\\)-distribution\n\nCompared two treatments using a paired \\(t\\)-test\n\nComputed confidence intervals\n\nUsed t.test() in R\n\nBut today I want to slow down and ask a more fundamental question:\n\nWhat is a statistical test actually doing?\n\nWhen you click Run on a \\(t\\)-test in R and see a p-value, what just happened?\nToday I want to dive more into every aspect of a statistical test. I believe this is a good place to do this because we will explore more complex tests and trial designs from now on, and the \\(t\\)-test provides a simple framework to explain these topics."
  },
  {
    "objectID": "posts/2026-02-19_understanding-statistical-tests/index.html#hypotheses",
    "href": "posts/2026-02-19_understanding-statistical-tests/index.html#hypotheses",
    "title": "Understanding Statistical Tests",
    "section": "Hypotheses",
    "text": "Hypotheses\nFrom the research question, we can draw the following competing statements.\n\\[H_0: \\mu_{rye} = \\mu_{no~rye} \\newline  \nH_a: \\mu_{rye} \\neq \\mu_{no~rye} \\]\nA statistical test does not prove Ha. It evaluates whether the data are compatible with \\(H_0\\)\nNotice that the alternative hypothesis (\\(H_a\\)) is compatible with the language used in the research question, which states whether there’s a difference in yield.\nIf the research question stated whether there’s a reduction in corn yield, our hypothesis would have to be adjusted. So far, in this course, I have not made that distinction to keep things simple, but we will explore this a little more in depth when we talk about one-sided versus two-sided \\(t\\)-tests."
  },
  {
    "objectID": "posts/2026-02-19_understanding-statistical-tests/index.html#the-linear-additive-model-behind-the-t-test",
    "href": "posts/2026-02-19_understanding-statistical-tests/index.html#the-linear-additive-model-behind-the-t-test",
    "title": "Understanding Statistical Tests",
    "section": "The Linear Additive Model Behind the \\(t\\)-Test",
    "text": "The Linear Additive Model Behind the \\(t\\)-Test\nUp to this point, we have written hypotheses using symbols. But underneath every hypothesis test is a model.\nFor the rye example, the paired \\(t\\)-test can be written as a linear additive model:\n\\[Y_{ij} = \\mu + \\tau_i + \\epsilon_{ij}\\] Where \\(i\\) indexes the treatment (rye, no rye), and \\(j\\) indexes the observation for that treatment (every strip).\nLet’s slow down and unpack this.\n\\(Y_{ij}\\) = observed yield\n\\(\\mu\\) = overall mean yield\n\\(\\tau_i\\) = treatment effect (rye or no rye)\n\\(\\varepsilon_{ij}\\) = random error\nThis equation says:\nObserved yield = overall average + treatment effect + random variability\n\nLooking deeper into the data\nLet’s take a look at the rye example and explore what each model parameter represents. As a reminder, let’s look at the data below:\n\n\n\n\n\n\n\n\n\nSince we were looking at the difference between paired plots, we can represent it as the difference between plots. In this plot, the open circles represent the individual differences for every pair, and the filled triangle represents the mean difference.\n\n\n\n\n\n\n\n\n\nRemember, we are testing for differences among the treatments. In summary, we are testing whether our difference is zero. Because we are analyzing paired differences, the overall mean cancels out, and the model simplifies to:\n\\[\\Delta Y_{ij} =  \\tau_i + \\epsilon_{ij}\\] And the hypothesis we are testing is:\n\\[H_0: \\tau_i = 0 \\newline  \nH_a:  \\tau_i \\neq 0\\]\nLet’s start with identifying \\(\\tau_i\\) first. Since \\(\\tau_i\\) is the mean difference between the treatments:\n\n\n\n\n\n\n\n\n\nOk, we were able to identify \\(\\tau_i\\) in the graph. So it’s easier to see, let’s spread the individual observations along the y-axis and identify the errors (\\(\\epsilon_{ij}\\)). The distance between the points and the \\(\\tau_i\\) line are the errors for each plot."
  },
  {
    "objectID": "posts/2026-02-19_understanding-statistical-tests/index.html#the-test-statistic",
    "href": "posts/2026-02-19_understanding-statistical-tests/index.html#the-test-statistic",
    "title": "Understanding Statistical Tests",
    "section": "The test statistic",
    "text": "The test statistic\nFor the paired \\(t\\)-test:\n\\[T = \\frac{\\bar{x} − \\mu}{\\frac{s}{\\sqrt{n}}} = \\frac{mean~difference − 0}{standard~error}\\]\nNotice:\n\nNumerator = signal\n\nDenominator = noise\n\nStatistical tests measure signal relative to variability.\nLarge signal relative to noise → large |T| → small p-value."
  },
  {
    "objectID": "posts/2026-02-19_understanding-statistical-tests/index.html#interpreting-the-t-test-output",
    "href": "posts/2026-02-19_understanding-statistical-tests/index.html#interpreting-the-t-test-output",
    "title": "Understanding Statistical Tests",
    "section": "Interpreting the \\(t\\)-test output",
    "text": "Interpreting the \\(t\\)-test output\nAfter running a paired \\(t\\)-test, you obtained:\n    Paired t-test\n\ndata:  rye_wide$Yield.Control and rye_wide$`Yield.Cereal Rye`\nt = 2.3366, df = 11, p-value = 0.03941\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n  0.3756842 12.5743158\nsample estimates:\nmean difference \n          6.475 \nRounding that p-value to 0.04, what does 0.04 actually mean?\nIt does NOT mean:\n\nThere is a 4% chance rye reduces yield\n\nThere is a 4% chance the null hypothesis is true\n\nThere is a 96% chance rye hurts yield\n\nIt means:\n\nIf there were truly no difference in yield between rye and no rye, we would observe a \\(t\\)-statistic this or more extreme only about 4% of the time due to random sampling variability."
  },
  {
    "objectID": "posts/2026-02-19_understanding-statistical-tests/index.html#type-i-and-type-ii-errors",
    "href": "posts/2026-02-19_understanding-statistical-tests/index.html#type-i-and-type-ii-errors",
    "title": "Understanding Statistical Tests",
    "section": "Type I and Type II Errors",
    "text": "Type I and Type II Errors\nSince we are dealing with randomness, each of these error sources have their own probability. Let’s take a look:\nType I Error:\n\nRejecting \\(H_0\\) when it is true.\nThis is a threshold we set when conducting the test.\nProbability = α (often 0.05).\n\nType II Error:\n\nFailing to reject \\(H_0\\) when it is false.\n\nThis is how often do we fail to identify a true effect.\nProbability = β.\n\nThese errors reflect uncertainty in decision-making."
  },
  {
    "objectID": "posts/2026-02-19_understanding-statistical-tests/index.html#thinking-of-this-trade-off",
    "href": "posts/2026-02-19_understanding-statistical-tests/index.html#thinking-of-this-trade-off",
    "title": "Understanding Statistical Tests",
    "section": "Thinking of this trade-off",
    "text": "Thinking of this trade-off\nWhen we decrease the significance level (\\(\\alpha\\)), we decrease the probability of Type I error. However, even if \\(H_0\\) is false, we need the \\(|T|\\) to be bigger in order to reject \\(H_0\\). Thus, we also decrease the power of our statistical test.\nLook at the plots below, for example, if we have 30 samples (\\(n=30\\)), going from \\(\\alpha=0.05\\) to \\(\\alpha=0.01\\), means that \\(|T|\\) needs to be more extreme than 2.75, instead of 2.05, making the test stricter.\n\nlibrary(fastGraph)\nx &lt;- seq(-3, 3, 0.1)\nt05 &lt;- qt(c(0.025, 0.975), 29)\nt01 &lt;- qt(c(0.005, 0.995), 29)\n\nshadeDist(t05, 'dt', parm2 = 29)\n\n\n\n\n\n\n\nshadeDist(t01, 'dt', parm2 = 29)\n\n\n\n\n\n\n\n\nIn agronomy, low power means:\n\nReal treatment effects may go undetected\n\nManagement recommendations may be based on insufficient replication\n\nPower depends on:\n\nEffect size\n\nVariability\n\nSample size\n\nSignificance level (α)\n\nMore replication → smaller standard error → greater power."
  },
  {
    "objectID": "posts/2026-02-19_understanding-statistical-tests/index.html#conducting-a-one-sided-t-test-in-r",
    "href": "posts/2026-02-19_understanding-statistical-tests/index.html#conducting-a-one-sided-t-test-in-r",
    "title": "Understanding Statistical Tests",
    "section": "Conducting a one-sided \\(t\\)-test in R",
    "text": "Conducting a one-sided \\(t\\)-test in R\nGreat, now we understand the difference between one-sided tests and two-sided tests. How do we implement them?\n\nrye &lt;- read.csv('./data/cover-crop.csv')\nryew &lt;- reshape(rye, \n                idvar = 'Block',\n                timevar = 'Treatment',\n                direction = 'wide')\nt.test(ryew$`Yield.Cereal Rye`,\n       ryew$Yield.Control, \n       paired = TRUE,\n       alternative = 'less')\n\n\n    Paired t-test\n\ndata:  ryew$`Yield.Cereal Rye` and ryew$Yield.Control\nt = -2.3366, df = 11, p-value = 0.01971\nalternative hypothesis: true mean difference is less than 0\n95 percent confidence interval:\n      -Inf -1.498288\nsample estimates:\nmean difference \n         -6.475"
  },
  {
    "objectID": "posts/2025-02-11_yield-map/index.html",
    "href": "posts/2025-02-11_yield-map/index.html",
    "title": "Working with yield monitor data",
    "section": "",
    "text": "Working with yield monitor data can be quite challenging. The data can have several sources of error and accounting for all of them can be hard. For instance, there are instances in which the combine travels through an area that has been previously harvested, artificially recording low yielding points. There can also uncertainties associated with the combine travelling fast or slow, changing the effective harvested area from one observation to the next. There are many other instances in which we can end up with inadequate data when working with yield monitor data but this blog post cannot list all of them.\nI wanted to give you an example of how we can use pacu to address some of these challenges. For that, we will use a data set contained in the agridat package."
  },
  {
    "objectID": "posts/2025-02-11_yield-map/index.html#introduction",
    "href": "posts/2025-02-11_yield-map/index.html#introduction",
    "title": "Working with yield monitor data",
    "section": "",
    "text": "Working with yield monitor data can be quite challenging. The data can have several sources of error and accounting for all of them can be hard. For instance, there are instances in which the combine travels through an area that has been previously harvested, artificially recording low yielding points. There can also uncertainties associated with the combine travelling fast or slow, changing the effective harvested area from one observation to the next. There are many other instances in which we can end up with inadequate data when working with yield monitor data but this blog post cannot list all of them.\nI wanted to give you an example of how we can use pacu to address some of these challenges. For that, we will use a data set contained in the agridat package."
  },
  {
    "objectID": "posts/2025-02-11_yield-map/index.html#installing-and-loading-the-necessary-packages",
    "href": "posts/2025-02-11_yield-map/index.html#installing-and-loading-the-necessary-packages",
    "title": "Working with yield monitor data",
    "section": "Installing and loading the necessary packages",
    "text": "Installing and loading the necessary packages\nIf you have not done so, you can install the agridat package using the following line of code:\n\ninstall.packages('agridat')\n\nTo install pacu, you can either install the CRAN version:\n\ninstall.packages('pacu')\n\nOr, you can install the development version from GitHub using the remotes package:\n\nremotes::install_github('cldossantos/pacu')\n\nNow that we have installed the necessary packages we can load them and continue with our analysis.\n\nlibrary(pacu)\nlibrary(sf)\nlibrary(agridat)"
  },
  {
    "objectID": "posts/2025-02-11_yield-map/index.html#working-with-the-data",
    "href": "posts/2025-02-11_yield-map/index.html#working-with-the-data",
    "title": "Working with yield monitor data",
    "section": "Working with the data",
    "text": "Working with the data\nThe agridat package contains a data set of yield observations collected from a corn field in Minnesota, the data set name is gartner.corn.\nHere, we load the data set and look at the first rows:\n\ndata(\"gartner.corn\")\nhead(gartner.corn)\n\n       long      lat  mass time seconds dist moist    elev\n1 -93.97842 43.92726 16.54    0       3  116  18.5 1030.58\n2 -93.97842 43.92723 22.52    3       3  159  16.7 1030.58\n3 -93.97842 43.92718 27.01    6       3  169  17.2 1029.92\n4 -93.97842 43.92713 30.24    9       3  221  17.2 1029.92\n5 -93.97842 43.92708 30.95   12       3  234  17.3 1029.59\n6 -93.97842 43.92702 33.57   15       3  227  17.5 1029.59\n\n\nThere are a couple pieces of information that we need but that are currently not included in the data set. Namely, we need the combine swath and the yield. In the help page the author provided more information that can come in handy. For instance, he told us that the combine swath is 360 inches and provided a formula to calculate yield from the information in the data set. The yield will be calculated in units of bushel/acre. Let’s follow his formula:\n\ngartner.corn$swath &lt;- 360\ngartner.corn$dry.grain &lt;-  with(gartner.corn, (mass * seconds * (100-moist) / (100-15.5)) / 56) \ngartner.corn$harvested.area &lt;-  with(gartner.corn, (dist * swath) / 6272640) \ngartner.corn$yield &lt;- with(gartner.corn, dry.grain / harvested.area)"
  },
  {
    "objectID": "posts/2025-02-11_yield-map/index.html#renaming-some-of-the-variables",
    "href": "posts/2025-02-11_yield-map/index.html#renaming-some-of-the-variables",
    "title": "Working with yield monitor data",
    "section": "Renaming some of the variables",
    "text": "Renaming some of the variables\nHere, I rename some of the variables so that it is easier for me to understand what they represent.\n\nnames(gartner.corn) &lt;- c('long', 'lat', 'flow', 'time', 'interval', 'distance', 'moisture', 'elevation', 'swath', 'dry.grain', 'harvested.area', 'yield')\n\nNow that we have added the necessary columns, we can convert the data frame into a sf object. The sf library has several methods for working with spatial data and pacu is heavily built upon those. We can also plot the data to look into the spatial patterns of the variables:\n\nyield.data &lt;- st_as_sf(gartner.corn, \n                       coords = c('long', 'lat'),\n                       crs = 'epsg:4326')\nplot(yield.data)"
  },
  {
    "objectID": "posts/2025-02-11_yield-map/index.html#looking-at-the-yield-data",
    "href": "posts/2025-02-11_yield-map/index.html#looking-at-the-yield-data",
    "title": "Working with yield monitor data",
    "section": "Looking at the yield data",
    "text": "Looking at the yield data\nIf we focus on the yield (bu/ac), we can see some interesting features of this field. It seems like there is a waterway in the northern part of the field and there is an area in the mid-lower east part of the field that has lower yields.\n\nplot(yield.data['yield'], pch = 15)\n\n\n\n\n\n\n\n\nSomething that can also catch our attention is just how variable this data is. Let’s take a look at the distribution of the data as well. We can see that most of the data is between 100 and 160 bu/ac but the data ranges from 0 to 258 bu/ac.\n\nplot(density(yield.data$yield), main = '')"
  },
  {
    "objectID": "posts/2025-02-11_yield-map/index.html#considerations-about-cleaning-the-data",
    "href": "posts/2025-02-11_yield-map/index.html#considerations-about-cleaning-the-data",
    "title": "Working with yield monitor data",
    "section": "Considerations about cleaning the data",
    "text": "Considerations about cleaning the data\nThis kind of variability can be dealt with a variety of approaches. There are researchers who have proposed that we can remove anything that falls outside of 2 or 3 standard deviations from the mean. This is an empirical rule based on the assumption that the yield data follows a normal distribution. These thresholds represent \\(\\approx95.0\\%\\) and \\(\\approx99.7\\%\\) of the probability mass function of a normal distribution, respectively. However, this is based on two assumptions that are violated from the beginning:\n\nIndependent samples: these are correlated in space\nNormal distribution: there is no guarantee this data will follow a normal distribution. These data are bound to be greater than zero.\n\nThere is ultimately no magical formula for cleaning yield data. Some of the empirical rules can work for some data sets but not for others. pacu offers options that do not rely on these rules but I feel that this is a subject for a different post."
  },
  {
    "objectID": "posts/2025-02-11_yield-map/index.html#producing-a-yield-map",
    "href": "posts/2025-02-11_yield-map/index.html#producing-a-yield-map",
    "title": "Working with yield monitor data",
    "section": "Producing a yield map",
    "text": "Producing a yield map\nTo produce a yield map using pacu, we will use the pa_yield() function. The package offers two algorithms: simple and ritas. In this post I will not go into much detail about the algorithms. There is more information about this in this paper.\nIn this case, I will go straight to the ritas algorithm. The ritas algorithm involves several computationally intensive processes. To accelerate this process, we have enabled parallelization. The user can control this using the cores argument. Keep in mind though that parallelization has diminishing returns!\nI did not supply units in this case because the pa_yield() function attempts to guess the units and I wanted to demonstrate that functionality. However, this is based on very simple rules and the function can make a mistake. In that case, the user can override the guess by passing the argument data.units.\n\nyld &lt;- pa_yield(input = yield.data, \n                algorithm = 'ritas',\n                unit.system = 'metric',\n                moisture.adj = 15.5,\n                cores = 5,\n                verbose = FALSE)\n\nGuessing units of interval to be s\n\n\nGuessing units of moisture to be %\n\n\nGuessing units of flow to be lb/s\n\n\nGuessing units of width to be in\n\n\nGuessing units of distance to be in\n\n\nTo look at the yield map, we can use the pa_plot() function.\n\npa_plot(yld, legend.outside = TRUE)"
  },
  {
    "objectID": "posts/2025-02-11_yield-map/index.html#conclusion",
    "href": "posts/2025-02-11_yield-map/index.html#conclusion",
    "title": "Working with yield monitor data",
    "section": "Conclusion",
    "text": "Conclusion\nWe have looked into how we can build yield maps from raw yield monitor data using pacu. This is a case in which we are processing the data at the field level. In a case in which we are processing data from on-farm experiments, there are a few more considerations we need to make. This is a subject for a future post!"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "CV",
    "section": "",
    "text": "If you have trouble visualizing the embeded CV, please click  here to download the pdf file."
  }
]